{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computational Learning Articles.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOL6TkKi+1QBcmMyMB4Wu3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbremont/Notas/blob/main/Ingenerare/Computational_Learning_Articles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXHJxLSKedNB"
      },
      "source": [
        "* [Neural Algorithms Reading Group](https://brabeeba.github.io/neuralReadingGroup/index.html)\n",
        "\n",
        "* [Machine learning](https://en.wikipedia.org/wiki/Machine_learning)\n",
        "\n",
        "* [The 4 Biggest Open Problems in NLP](https://ruder.io/)\n",
        "\n",
        "* [What data on myself I collect and why? | beepb00p](https://beepb00p.xyz/my-data.html#what)\n",
        "\n",
        "* [What does it mean for the training data to be generated by a probability distribution over datasets](https://stats.stackexchange.com/questions/320375/what-does-it-mean-for-the-training-data-to-be-generated-by-a-probability-distrib)\n",
        "\n",
        "\n",
        "* [Multimodal Neurons in Artificial Neural Networks](https://openai.com/blog/multimodal-neurons/)\n",
        "\n",
        "* [Neural Networks 1](https://cs231n.github.io/neural-networks-1/)\n",
        "\n",
        "* [Neural Networks Case Study](https://cs231n.github.io/neural-networks-case-study/)\n",
        "\n",
        "* [Nonlinear system](https://en.wikipedia.org/wiki/Nonlinear_system)\n",
        "\n",
        "* [Numerical control](https://en.wikipedia.org/wiki/Numerical_control)\n",
        "\n",
        "* [Optimization 1](https://cs231n.github.io/optimization-1/)\n",
        "\n",
        "* [Point estimation](https://en.wikipedia.org/wiki/Point_estimation)\n",
        "\n",
        "* [Predictive analytics](https://en.wikipedia.org/wiki/Predictive_analytics)\n",
        "\n",
        "* [How to fit an elephant](https://www.johndcook.com/blog/2011/06/21/how-to-fit-an-elephant/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CUuDBuwege6"
      },
      "source": [
        "* [Markov chain](https://en.wikipedia.org/wiki/Markov_chain)\n",
        "\n",
        "* [Markov decision process](https://en.wikipedia.org/wiki/Markov_decision_process)\n",
        "\n",
        "* [Mathematical problem](https://en.wikipedia.org/wiki/Mathematical_problem)\n",
        "\n",
        "* [Mathematical statistics](https://en.wikipedia.org/wiki/Mathematical_statistics)\n",
        "\n",
        "* [Mathematics of Sudoku](https://en.wikipedia.org/wiki/Mathematics_of_Sudoku)\n",
        "\n",
        "* [Limits of statistics](https://www.johndcook.com/blog/2012/09/07/limits-of-statistics/)\n",
        "\n",
        "* [Linear Classification](https://cs231n.github.io/linear-classify/)\n",
        "\n",
        "- [Algorithmic Information Theory](http://www.hutter1.net/ait.htm)\n",
        "\n",
        "- [Deep reinforcement learning will transform manufacturing as we know it](https://techcrunch.com/2021/06/17/deep-reinforcement-learning-will-transform-manufacturing-as-we-know-it/)\n",
        "  - [Discussion](https://news.ycombinator.com/item?id=27557856)\n",
        "\n",
        "- [t-statistic](https://en.wikipedia.org/wiki/T-statistic)\n",
        "\n",
        "- [Understanding p-values Through Simulations](https://rpsychologist.com/pvalue/)\n",
        "\n",
        "- [Understanding Q-Q Plots](https://data.library.virginia.edu/understanding-q-q-plots/)\n",
        "\n",
        "- [Student's t-distribution](https://en.wikipedia.org/wiki/Student's_t-distribution)\n",
        "\n",
        "- [Summary statistics](https://en.wikipedia.org/wiki/Summary_statistics)\n",
        "\n",
        "- [Survivorship bias](https://en.wikipedia.org/wiki/Survivorship_bias)\n",
        "\n",
        "- [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/)\n",
        "\n",
        "- [Standard deviation](https://en.wikipedia.org/wiki/Standard_deviation)\n",
        "\n",
        "- [Statistical dispersion](https://en.wikipedia.org/wiki/Statistical_dispersion)\n",
        "\n",
        "- [Why I've lost faith in p values](https://lucklab.ucdavis.edu/blog/2018/4/19/why-i-lost-faith-in-p-values)\n",
        "\n",
        "- [What is P-Value? – Understanding the meaning, math and methods](https://www.machinelearningplus.com/what-is-p-value/)\n",
        "\n",
        "- [Robust statistics](https://en.wikipedia.org/wiki/Robust_statistics)\n",
        "\n",
        "- [Simpson's paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)\n",
        "\n",
        "- [Skewness](https://en.wikipedia.org/wiki/Skewness)\n",
        "\n",
        "- [Open-high-low-close chart](https://en.wikipedia.org/wiki/Open-high-low-close_chart)\n",
        "\n",
        "- [P Values](https://www.statsdirect.com/help/basics/p_values.htm)\n",
        "\n",
        "- [p-values are inconsistent](https://www.johndcook.com/blog/2010/03/03/p-values-are-inconsistent/)\n",
        "\n",
        "- [How to test my data against an specific normal distribution?](https://stats.stackexchange.com/questions/56106/how-to-test-my-data-against-an-specific-normal-distribution)\n",
        "\n",
        "- [Moving Average](https://en.wikipedia.org/wiki/Moving_average)\n",
        "\n",
        "- [Misinterpretations and misuses of p-values](https://web.ma.utexas.edu/users/mks/statmistakes/misinterppvalues.html)\n",
        "\n",
        "* [Kolmogorov–Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)\n",
        "\n",
        "- [Ecological fallacy](https://en.wikipedia.org/wiki/Ecological_fallacy)\n",
        "\n",
        "- [Good, mediocre, and bad p-values](https://statmodeling.stat.columbia.edu/2015/04/30/good-mediocre-bad-p-values/)\n",
        "\n",
        "* [Kernel (statistics)](https://en.wikipedia.org/wiki/Kernel_(statistics))\n",
        "\n",
        "- [Deviation (statistics)](https://en.wikipedia.org/wiki/Deviation_(statistics))\n",
        "\n",
        "- [A Litany of Problems With p-values](https://www.fharrell.com/post/pval-litany/)\n",
        "\n",
        "- [Accuracy and precision](https://en.wikipedia.org/wiki/Accuracy_and_precision)\n",
        "\n",
        "- [Data-generating probability distribution, probability distribution of a dataset, in ML](https://datascience.stackexchange.com/questions/54346/data-generating-probability-distribution-probability-distribution-of-a-dataset)\n",
        "  - How can i used a  probability distribution to generate data.\n",
        "\n",
        "- [Explaining p-values with puppies](https://hackernoon.com/explaining-p-values-with-puppies-af63d68005d0)\n",
        "\n",
        "- [Friends don’t let friends calculate p-values (without fully understanding them)](http://www.scottbot.net/HIAL/index.html@p=24697.html)\n",
        "\n",
        "- [Generative model](https://en.wikipedia.org/wiki/Generative_model)\n",
        "\n",
        "- [Statistical model](https://en.wikipedia.org/wiki/Statistical_model)\n",
        "\n",
        "- [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)\n",
        "\n",
        "- [Average](https://en.wikipedia.org/wiki/Average)\n",
        "\n",
        "- [Average absolute deviation](https://en.wikipedia.org/wiki/Average_absolute_deviation)\n",
        "\n",
        "- [Box plot](https://en.wikipedia.org/wiki/Box_plot)\n",
        "\n",
        "- [Coefficient of variation](https://en.wikipedia.org/wiki/Coefficient_of_variation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXSWs9CiejNu"
      },
      "source": [
        "* [Statistics (scipy.stats)](https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html#t-test-and-ks-test)\n",
        "\n",
        "* [scipy.stats.ttest_1samp](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html)\n",
        "\n",
        "* [p-value](https://en.wikipedia.org/wiki/P-value)\n",
        "\n",
        "* [Exclusion of the null hypothesis](https://en.wikipedia.org/wiki/Exclusion_of_the_null_hypothesis)\n",
        "\n",
        "* [Standard error](https://en.wikipedia.org/wiki/Standard_error)\n",
        "\n",
        "* [t-statistic](https://en.wikipedia.org/wiki/T-statistic)\n",
        "\n",
        "* [A Visual Exploration of Gaussian Processes](https://distill.pub/2019/visual-exploration-gaussian-processes/)\n",
        "\n",
        "* [Standard deviation](https://en.wikipedia.org/wiki/Standard_deviation)\n",
        "\n",
        "* [Log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution)\n",
        "\n",
        "* [Fat-tailed distribution](https://en.wikipedia.org/wiki/Fat-tailed_distribution)\n",
        "\n",
        "* [Taleb distribution](https://en.wikipedia.org/wiki/Taleb_distribution)\n",
        "\n",
        "* [Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution)\n",
        "\n",
        "* [Forecasting at Uber: An Introduction](https://eng.uber.com/forecasting-introduction/)\n",
        "\n",
        "* [Introducing Ludwig, a Code-Free Deep Learning Toolbox](https://eng.uber.com/introducing-ludwig/)\n",
        "\n",
        "* [Why are neural networks so powerful?](https://towardsdatascience.com/why-are-neural-networks-so-powerful-bc308906696c)\n",
        "\n",
        "* [EigenGame maps out a new approach to solve fundamental ML problems](https://deepmind.com/blog/article/EigenGame)\n",
        "\n",
        "* [An Introduction to Knowledge Graphs](http://ai.stanford.edu/blog/introduction-to-knowledge-graphs/)\n",
        "\n",
        "* [Resources | The Little Dataset](https://thelittledataset.com/data_code/)\n",
        "\n",
        "* [Knowledge Graph](https://en.wikipedia.org/wiki/Knowledge_graph)\n",
        "\n",
        "* [Andrew Ng X-Rays the AI Hype](https://arstechnica.com/gadgets/2021/05/apple-hires-yet-another-ex-google-ai-leader/)\n",
        "\n",
        "* [Hopfield Networks is All You Need](http://justinjaffray.com/query-engines-push-vs.-pull/)\n",
        "\n",
        "* [Principal Component Analysis](https://setosa.io/ev/principal-component-analysis/)\n",
        "\n",
        "* [ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus](https://www.inference.vc/untitled/)\n",
        "\n",
        "* [No free lunch theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem)\n",
        "\n",
        "* [Automated machine learning (AutoML)](https://en.wikipedia.org/wiki/Automated_machine_learning)\n",
        "\n",
        "* [Search: Query Matching via Lexical, Graph, and Embedding Methods](https://eugeneyan.com/writing/search-query-matching/)\n",
        "\n",
        "* [Geometric foundations of Deep Learning](https://towardsdatascience.com/geometric-foundations-of-deep-learning-94cdd45b451d)\n",
        "\n",
        "* [A recommender system for scientific papers](https://statmodeling.stat.columbia.edu/2021/04/16/a-recommender-system-for-scientific-papers/)\n",
        "\n",
        "* [Machine Learning 101](https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview?pru=AAABdHL9X3A*1T5cE4vF1wtY7TY9Pe5d5A&slide=id.g168a3288f7_0_58)\n",
        "\n",
        "* [Brian Kihoon Lee -  My Path to Machine Learning](https://www.moderndescartes.com/essays/my_ml_path/)\n",
        "\n",
        "* [How I taught myself Deep Learning: Vanilla NNs](https://www.kaggle.com/andradaolteanu/how-i-taught-myself-deep-learning-vanilla-nns)\n",
        "\n",
        "* [Why is machine learning 'hard'?](http://ai.stanford.edu/~zayd/why-is-machine-learning-hard.html)\n",
        "\n",
        "* [The Data Science Tree of Knowledge - What is Data Science and How to Educate Data Scientists](https://pabloinsente.github.io/ds-tree-knowledge)\n",
        "\n",
        "* Machine Learning Crash course\n",
        "  - [Part 1 - The basics of machine learning - regression, cost functions, and gradient descent.](https://ml.berkeley.edu/blog/posts/crash-course/part-1/)\n",
        "  - [Part 2 - Perceptrons, logistic regression, and SVMs.](https://ml.berkeley.edu/blog/posts/crash-course/part-2/)\n",
        "  - [Part 3 - Neural networks.](https://ml.berkeley.edu/blog/posts/crash-course/part-3/)\n",
        "  - [Part 4 - The Bias-Variance Dilemma.](https://ml.berkeley.edu/blog/posts/crash-course/part-4/)\n",
        "  - [Part 5 - Decision trees and ensemble models.](https://ml.berkeley.edu/blog/posts/crash-course/part-5/)\n",
        "\n",
        "* [Python Numpy Tutorial](https://cs231n.github.io/python-numpy-tutorial/)\n",
        "* [NumPy Fundamentals for Data Science and Machine Learning](https://pabloinsente.github.io/intro-numpy-fundamentals)\n",
        "\n",
        "* [Google Colab Tips for Power Users](https://amitness.com/2020/06/google-colaboratory-tips)\n",
        "\n",
        "\n",
        "* [An introduction to reinforcement learning](https://colab.research.google.com/github/psc-g/intro_to_rl/blob/master/Introduction_to_reinforcement_learning.ipynb)\n",
        "\n",
        "* [Using NLP to allow for flatter organizations](https://middle-out.io/posts/nlp_orgs) \n",
        "\n",
        "* [Universal approximation theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem)\n",
        "\n",
        "* [Multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron)\n",
        "\n",
        "\n",
        "* [Modern Deep Learning Techniques Applied to Natural Language Processing ](https://nlpoverview.com/)\n",
        "\n",
        "\n",
        "* [Backpropagation](https://brilliant.org/wiki/backpropagation/)\n",
        "\n",
        "\n",
        "* [Statistical model](https://en.wikipedia.org/wiki/Statistical_model)\n",
        "\n",
        "* [Statistics](https://en.wikipedia.org/wiki/Statistics)\n",
        "\n",
        "* [User modeling](https://en.wikipedia.org/wiki/User_modeling)\n",
        "\n",
        "* [Introduction to Bayesian Inference](https://www.kaggle.com/philippsinger/introduction-to-bayesian-inference)\n",
        "\n",
        "* [Approaching (Almost) Any NLP Problem on Kaggle](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle)\n",
        "\n",
        "\n",
        "* [Pattern recognition](https://en.wikipedia.org/wiki/Pattern_recognition)\n",
        "\n",
        "* (D) [AI Data Architecture](http://0.0.0.0:8000/2%20Aprendisaje%20Automatico/Articulos/AI%20Data%20Architecture.pdf)\n",
        "\n",
        "* (D) [Artificial Intelligence and Machine Learning](http://0.0.0.0:8000/2%20Aprendisaje%20Automatico/Articulos/Artificial%20Intelligence%20and%20Machine%20Learning.pdf)\n",
        "\n",
        "\n",
        "* [A simple solution for monitoring ML systems](https://www.jeremyjordan.me/ml-monitoring/)\n",
        "\n",
        "* [What does a data-generating process (DGP) actually mean?](https://stats.stackexchange.com/questions/443320/what-does-a-data-generating-process-dgp-actually-mean)\n",
        "\n",
        "* [Simple PyTorch Transformer Example with Greedy Decoding](https://colab.research.google.com/drive/1swXWW5sOLW8zSZBaQBYcGQkQ_Bje_bmI#scrollTo=b6eCpl-ne7tj)\n",
        "\n",
        "* [The limitations of deep learning](https://blog.keras.io/the-limitations-of-deep-learning.html)\n",
        "\n",
        "* [The future of deep learning](https://blog.keras.io/the-future-of-deep-learning.html)\n",
        "\n",
        "* [Baselines ML](https://madewithml.com/courses/applied-ml/baselines/)\n",
        "\n",
        "\n",
        "* [What does a data-generating process (DGP) actually mean?](https://stats.stackexchange.com/questions/443320/what-does-a-data-generating-process-dgp-actually-mean)\n",
        "\n",
        "\n",
        "* [Question answering](https://en.wikipedia.org/wiki/Question_answering)\n",
        "\n",
        "* [Can I use Deep Learning for that?](https://marksaroufim.medium.com/can-deep-learning-solve-my-problem-a-type-theoretic-heuristic-e57f4d1658f)\n",
        "\n",
        "* [Inference engine](https://en.wikipedia.org/wiki/Inference_engine)\n",
        "\n",
        "* [5 Open Problems In NLP](https://deeps.site/blog/2019/09/09/nlp-problems/)\n",
        "\n",
        "* [A Computational Model for Intelligent Manufacturin](https://industrytoday.com/a-computational-model-for-intelligent-manufacturing/)\n",
        "\n",
        "* [A top-down, practical guide to learn AI, Deep learning and Machine Learning](https://github.com/emilwallner/How-to-learn-Deep-Learning)\n",
        "\n",
        "* [AMA: Michael I Jordan](https://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)\n",
        "\n",
        "* [An Introduction to Hierarchical Modeling](http://mfviz.com/hierarchical-models/)\n",
        "\n",
        "* [An Overview of Deep Learning for Curious People](https://lilianweng.github.io/lil-log/2017/06/21/an-overview-of-deep-learning.html)\n",
        "\n",
        "* [An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/)\n",
        "\n",
        "* [Analyze your WhatsApp Chat](https://community.wolfram.com/groups/-/m/t/2063174)\n",
        "\n",
        "* [Artificial Neural Nets Finally Yield Clues to How Brains Learn](https://www.quantamagazine.org/artificial-neural-nets-finally-yield-clues-to-how-brains-learn-20210218/)\n",
        "\n",
        "* [Attention and Memory in Deep Learning and NLP](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)\n",
        "\n",
        "* [Auto training and fast deployement for state-of-the-art NLP models](https://huggingface.co/autonlp)\n",
        "\n",
        "* [Automating My Job with GPT-3](https://blog.seekwell.io/gpt3)\n",
        "\n",
        "* [Cancer can be precisely diagnosed using a urine test with artificial intelligence](https://phys.org/news/2021-01-cancer-precisely-urine-artificial-intelligence.html)\n",
        "\n",
        "* [Cannes: How ML saves us $1.7M a year on document previews](https://dropbox.tech/machine-learning/cannes--how-ml-saves-us--1-7m-a-year-on-document-previews)\n",
        "\n",
        "\n",
        "* [Categorical Foundations of Gradient-Based Learning](https://www.brunogavranovic.com/posts/2021-03-03-Towards-Categorical-Foundations-Of-Neural-Networks.html)\n",
        "\n",
        "* [Causal model](https://en.wikipedia.org/wiki/Causal_model)\n",
        "\n",
        "* [Cellular automaton](https://en.wikipedia.org/wiki/Cellular_automaton)\n",
        "\n",
        "* [Centrifugal governor](https://en.wikipedia.org/wiki/Centrifugal_governor)\n",
        "\n",
        "* [Ceteris paribus](https://en.wikipedia.org/wiki/Ceteris_paribus)\n",
        "\n",
        "* [Color model](https://en.wikipedia.org/wiki/Color_model)\n",
        "\n",
        "* [Cheap PCB story](https://github.com/hardenedlinux/cheap-pcb/blob/main/cheap-pcb-story.md)\n",
        "\n",
        "* [Chinese restaurant process](https://en.wikipedia.org/wiki/Chinese_restaurant_process)\n",
        "\n",
        "* [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)\n",
        "\n",
        "* [Relations and differences between time-series analysis and statistical signal processing? - Cross Validated](https://stats.stackexchange.com/questions/52270/relations-and-differences-between-time-series-analysis-and-statistical-signal-pr)\n",
        "* [Keynesian beauty contest](https://en.wikipedia.org/wiki/Keynesian_beauty_contest)\n",
        "* [Time series](https://en.wikipedia.org/wiki/Time_series)\n",
        "* [What's the point of time series analysis?](https://stats.stackexchange.com/questions/367590/whats-the-point-of-time-series-analysis)\n",
        "* [How to Write a Neurips Paper 1. voodoo rituals to procure research… | by Evan Pu | Jan, 2021 | Medium](https://evanthebouncy.medium.com/how-to-write-a-neurips-paper-1-5b25a64d1d03)\n",
        "* [Machine Learning: The Great Stagnation - Breaking the Stagnation](https://marksaroufim.substack.com/p/machine-learning-the-great-stagnation)\n",
        "* [The Sovereign Student - Breaking the Stagnation](https://marksaroufim.substack.com/p/the-sovereign-student)\n",
        "* [No BS Machine Learning News - Breaking the Stagnation](https://marksaroufim.substack.com/p/coming-soon)\n",
        "\n",
        "* [Word Embeddings: The Good, the Bad, and the Ugly](https://medium.com/ontologik/word-embeddings-the-good-the-bad-and-the-ugly-ad67ada0e688)\n",
        "\n",
        "* [NLU and Natural Language Interfaces to Databases](https://medium.com/ontologik/nlu-and-natural-language-interfaces-to-databases-d04c3f032949)\n",
        "\n",
        "* [Data, Information, Knowledge, and GPT-3](https://medium.com/ontologik/data-information-knowledge-and-gpt-3-5e422107b46b)\n",
        "\n",
        "* [Semantics, Ambiguity, and the role of Probability in NLU](https://medium.com/ontologik/semantics-ambiguity-and-the-role-of-probability-in-nlu-e8e92fc7e8ed)\n",
        "\n",
        "* [Language & Cognition: re-reading Jerry Fodor](https://medium.com/ontologik/language-cognition-re-reading-jerry-fodor-53e98c9933f4)\n",
        "\n",
        "* [What we learn vs. what we know](https://medium.com/ontologik/what-we-learn-vs-what-we-know-1569e3fac3c9)\n",
        "\n",
        "* [Time to put an end to BERTology (or, ML/DL is not even relevant to NLU)](https://medium.com/ontologik/time-to-put-an-end-to-bertology-or-ml-dl-is-not-even-relevant-to-nlu-e5ba6fc53403)\n",
        "\n",
        "* [In NLU, you ignore intenSion at your peril](https://medium.com/ontologik/in-nlu-you-ignore-intension-at-your-peril-dd173670660d)\n",
        "\n",
        "* [Cognitive and Universal Primitives of the Language of Thought](https://medium.com/ontologik/cognitive-and-universal-primitives-of-the-language-of-thought-4be67096f9bc)\n",
        "\n",
        "* [Memorizing vs. Understanding (read: Data vs. Knowledge)](https://medium.com/ontologik/memorizing-vs-understanding-read-data-vs-knowledge-d27c5c756740)\n",
        "\n",
        "* [How the Tech Giants are Hampering Progress in Artificial Intelligence and Cognitive Computing](https://medium.com/ontologik/how-the-tech-giants-are-hampering-progress-in-artificial-intelligence-and-cognitive-computing-6a7ece7c9623)\n",
        "\n",
        "* [Learning from Data/Observations is Overrated](https://medium.com/ontologik/learning-from-data-observations-is-overrated-329a20d9fac1)\n",
        "\n",
        "* [The ‘transfer learning’ problem in DL: a NN is a hardware implementation of a specific algorithm](https://medium.com/ontologik/the-transferability-problem-in-neural-networks-a-nn-is-just-the-hardware-that-implements-a-6e3e54d00172)\n",
        "\n",
        "* [An Embarrassing Challenge for So-Called AI ‘Experts’ (of the ML/DL Ilk)](https://medium.com/ontologik/an-embarrassing-challenge-for-so-called-ai-experts-of-the-ml-dl-ilk-430541838d0a)\n",
        "\n",
        "* [Progressives Beware: Vote for the Neoliberals is a Vote for the Fascists and the Far-Right](https://medium.com/@ontologik/progressives-beware-vote-for-the-neoliberals-is-a-vote-for-the-fascists-and-the-far-right-c87551f6c5b3)\n",
        "\n",
        "* [No Walls in the Global Village](https://medium.com/platopia/no-walls-in-the-global-village-7968afd9a2a8)\n",
        "\n",
        "* [NLU is not NLP++](https://medium.com/ontologik/nlu-is-not-nlp-617f7535a92e)\n",
        "\n",
        "* [Data Science? All we Did is Just Replace the ‘Knowledge Bottleneck’ With a ‘Data Bottleneck’](https://medium.com/ontologik/data-science-all-we-did-is-just-replace-the-knowledge-bottleneck-with-a-data-bottleneck-b40c0e642541)\n",
        "\n",
        "* [Let’s Not Forget the ‘Science’ in ‘Computer Science’](https://medium.com/ontologik/lets-not-forget-the-science-in-computer-science-239d04f4d9a8)\n",
        "\n",
        "* [(Almost) Automatic Programming: Recursive Thinking as the Easiest Problem Solving Method](https://medium.com/ontologik/almost-automatic-programming-recursive-thinking-as-the-easiest-problem-solving-method-c4204beb01b0)\n",
        "\n",
        "* [Why Ambiguity is Necessary, and why Natural Language is not Learnable](https://medium.com/ontologik/why-ambiguity-is-necessary-and-why-natural-language-is-not-learnable-79f0e719ac78)\n",
        "\n",
        "* [Types, Ontology, and a Solution to the (so-called) Paradox of the Ravens](https://medium.com/ontologik/a-solution-to-the-so-called-paradox-of-the-ravens-defdf1ff9b13)\n",
        "\n",
        "* [The Unrelenting Ghosts of Fodor and Frege: 4 Technical Reasons why Data-Driven and Machine Learning NLU is a Myth](https://medium.com/ontologik/the-unrelenting-ghosts-of-fodor-and-frege-4-technical-reasons-why-data-driven-and-machine-d72698c22775)\n",
        "\n",
        "* [A Knowledge Graph?](https://medium.com/ontologik/a-knowledge-graph-981d4b7bc605)\n",
        "\n",
        "* [Must-read papers on graph neural networks (GNN)](https://github.com/thunlp/GNNPapers)\n",
        "\n",
        "* [The Unrelenting Ghosts of Fodor and Frege: 4 Technical Reasons why Data-Driven and Machine Learning NLU is a Myth](https://medium.com/@ontologik/the-unrelenting-ghosts-of-fodor-and-frege-4-technical-reasons-why-data-driven-and-machine-c2d02be144e9)\n",
        "\n",
        "* [(Almost) Automatic Programming: Recursion is a lot easier than you think](https://medium.com/@ontologik/almost-automatic-programming-recursion-is-a-lot-easier-than-you-think-49aa4efb6de)\n",
        "\n",
        "* [A Solution to the so-called Paradox of the Ravens](https://medium.com/@ontologik/a-solution-to-the-so-called-paradox-of-the-ravens-e257d051d0f0)\n",
        "\n",
        "* [Are NNs Just Fuzzy Hashtables? A Revealing Experiment on MNIST Data](https://medium.com/@ontologik)\n",
        "\n",
        "* [You Don't Really Need Another MOOC](https://eugeneyan.com/writing/you-dont-need-another-mooc/)\n",
        "\n",
        "* [Your Thinking Rate Is Fixed](https://fs.blog/2021/03/thinking-rate-fixed/)\n",
        "\n",
        "* [Zero to Hero (Machine Learning)](https://www.notes2tree.com/published_tree/?publish_tree=caiMJEsnCQ)\n",
        "\n",
        "\n",
        "\n",
        "* [Convolution](https://en.wikipedia.org/wiki/Convolution)\n",
        "\n",
        "* [Cross-correlation](https://en.wikipedia.org/wiki/Cross-correlation)\n",
        "\n",
        "* [Probabilistic Programming](https://simons.berkeley.edu/sites/default/files/docs/5675/talkprintversion.pdf)\n",
        "\n",
        "* [Basics statistics](http://www.mit.edu/~6.s085/notes/lecture1.pdf)\n",
        "\n",
        "* [Confidence intervals and hypothesis tests](http://www.mit.edu/~6.s085/notes/lecture2.pdf)\n",
        "\n",
        "* [Linear Regression](http://www.mit.edu/~6.s085/notes/lecture3.pdf)\n",
        "\n",
        "* [Regression Diagnostics and Advanced Regression Topics](http://www.mit.edu/~6.s085/notes/lecture4.pdf)\n",
        "\n",
        "* [Nonparametric statistics and model selection](http://www.mit.edu/~6.s085/notes/lecture5.pdf)\n",
        "\n",
        "* [Categorical data](http://www.mit.edu/~6.s085/notes/lecture6.pdf)\n",
        "\n",
        "* [Experimental Design](http://www.mit.edu/~6.s085/notes/lecture7.pdf)\n",
        "\n",
        "* [Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites](https://webtransparency.cs.princeton.edu/dark-patterns/)\n",
        "\n",
        "\n",
        "\n",
        "* [Data-generating probability distribution, probability distribution of a dataset, in ML](https://datascience.stackexchange.com/questions/54346/data-generating-probability-distribution-probability-distribution-of-a-dataset)\n",
        "\n",
        "\n",
        "\n",
        "* [Declarative Graphing](https://srush.github.io/dex-lang/examples/plotting.html)\n",
        "\n",
        "* [Deep Learning: Our Miraculous Year 1990-1991](https://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html)\n",
        "\n",
        "* [ebhy/budgetml: Deploy a ML inference service on a budget in less than 10 lines of code.](https://github.com/ebhy/budgetml)\n",
        "\n",
        "\n",
        "* [Feature learning](https://en.wikipedia.org/wiki/Feature_learning)\n",
        "\n",
        "\n",
        "* [Gary Marcus -  What Nate Silver Gets Wrong](https://www.newyorker.com/books/page-turner/what-nate-silver-gets-wrong)\n",
        "\n",
        "* [Gaussian process](https://en.wikipedia.org/wiki/Gaussian_process)\n",
        "\n",
        "* [Generalized Language Models](https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html)\n",
        "\n",
        "\n",
        "* [graph - Generating statistics from Git repository - Stack Overflow](https://stackoverflow.com/questions/1828874/generating-statistics-from-git-repository)\n",
        "\n",
        "* [Graph theory, graph convolutional networks, knowledge graphs](https://albertazout.substack.com/p/gradient-ascent-10)\n",
        "\n",
        "* [Graphics processing unit](https://en.wikipedia.org/wiki/Graphics_processing_unit)\n",
        "\n",
        "* [Graphite - Architecture](https://www.aosabook.org/en/graphite.html)\n",
        "\n",
        "* [THE UNIVERSAL APPROXIMATION THEOREM FOR NEURAL NETWORKS](https://mcneela.github.io/machine_learning/2017/03/21/Universal-Approximation-Theorem.html)\n",
        "\n",
        "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n",
        "* [Threat Modeling Manifesto](http://www.threatmodelingmanifesto.org/)\n",
        "\n",
        "* [Time series](https://en.wikipedia.org/wiki/Time_series#Models)\n",
        "\n",
        "\n",
        "* [Understanding Convolutional Neural Networks for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)\n",
        "\n",
        "* [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "* [Automated scientific research](https://www.youtube.com/watch?v=uLx0gyhVWDo)\n",
        "\n",
        "* [Nonparametric statistics](https://en.wikipedia.org/wiki/Nonparametric_statistics)\n",
        "\n",
        "* [Deep Learning: mathematics and neuroscience](http://cbmm.mit.edu/sites/default/files/publications/Deep%20Learning-%20mathematics%20and%20neuroscience.pdf)\n",
        "\n",
        "* [What are the connections between machine learning and signal processing?](https://www.quora.com/What-are-the-connections-between-machine-learning-and-signal-processing)\n",
        "\n",
        "* [The Genesis Enterprise: Taking Artificial Intelligence to another Level via a Computational Account of Human Story Understanding.pdf](https://dspace.mit.edu/bitstream/handle/1721.1/119651/CMHI-Report-1.pdf?sequence=1&isAllowed=y)\n",
        "\n",
        "* [Frontiers in Natural Language Processing Expert Responses](https://docs.google.com/document/d/18NoNdArdzDLJFQGBMVMsQ-iLOowP1XXDaSVRmYN0IyM/edit#)\n",
        "\n",
        "* [Statistic](https://en.wikipedia.org/wiki/Statistic)\n",
        "\n",
        "\n",
        "\n",
        "* [The Fibonacci Sequence as a Functor](https://www.math3ma.com/blog/fibonacci-sequence)\n",
        "\n",
        "* [Offline Reinforcement Learning:  From Algorithms to Practical Challenges](https://sites.google.com/view/offlinerltutorial-neurips2020/home)\n",
        "\n",
        "* [Free energy principle](https://en.wikipedia.org/wiki/Free_energy_principle)\n",
        "\n",
        "* [Markov blanket](https://en.wikipedia.org/wiki/Markov_blanket)\n",
        "\n",
        "* [Generative model](https://en.wikipedia.org/wiki/Generative_model)\n",
        "\n",
        "* [Discriminative model](https://en.wikipedia.org/wiki/Discriminative_model)\n",
        "\n",
        "* [Markov model](https://en.wikipedia.org/wiki/Markov_model)\n",
        "\n",
        "* [Markov Chains](https://brilliant.org/wiki/markov-chains/)\n",
        "\n",
        "* [Markov Model of Natural Language](https://www.cs.princeton.edu/courses/archive/spr05/cos126/assignments/markov.html)\n",
        "* [List of datasets for machine-learning research](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Signal_data)\n",
        "\n",
        "* [Inductive bias](https://en.wikipedia.org/wiki/Inductive_bias)\n",
        "\n",
        "* [Abductive reasoning](https://en.wikipedia.org/wiki/Abductive_reasoning)\n",
        "\n",
        "* [Inductive reasoning](https://en.wikipedia.org/wiki/Inductive_reasoning)\n",
        "\n",
        "* [Deductive reasoning](https://en.wikipedia.org/wiki/Deductive_reasoning)\n",
        "\n",
        "* [Variational inference in Bayesian neural networks](http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)\n",
        "\n",
        "* [Bayes by Backprop from scratch (NN, classification)](https://gluon.mxnet.io/chapter18_variational-methods-and-uncertainty/bayes-by-backprop.html)\n",
        "\n",
        "* [World Models Can agents learn inside of their own dreams?](https://worldmodels.github.io/)\n",
        "\n",
        "* [Andre Gelman -  Reflections on Breiman’s Two Cultures of Statistical Modeling](https://www.youtube.com/watch?v=10OV3mucmqc)\n",
        "\n",
        "* [GitHub - thunlp/PLMpapers: Must-read Papers on pre-trained language models.](https://github.com/thunlp/PLMpapers)\n",
        "\n",
        "* [Decoded: GNU coreutils](https://www.maizure.org/projects/decoded-gnu-coreutils/)\n",
        "\n",
        "* [How Difficult is your Programming Project?](https://www.maizure.org/projects/how-difficult-is-your-programming-project.html)\n",
        "\n",
        "* [I don't want to learn your garbage query language](https://erikbern.com/2018/08/30/i-dont-want-to-learn-your-garbage-query-language.html)\n",
        "\n",
        "* [Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)\n",
        "\n",
        "* [Statistical Mistakes and How to Avoid Them](https://www.cs.cornell.edu/~asampson/blog/statsmistakes.html)\n",
        "\n",
        "* [The Control Group Is Out Of Control](https://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/)\n",
        "\n",
        "* [The Control Group Is Out Of Control - HN](https://news.ycombinator.com/item?id=13025496)\n",
        "\n",
        "* [Road Map for Choosing Between Statistical Modeling and Machine Learning](https://www.fharrell.com/post/stat-ml/)\n",
        "\n",
        "\n",
        "\n",
        "* [Diffusion of innovations](https://en.wikipedia.org/wiki/Diffusion_of_innovations)\n",
        "\n",
        "* [Adaptive system](https://en.wikipedia.org/wiki/Adaptive_system)\n",
        "\n",
        "* [Co-occurrence](https://en.wikipedia.org/wiki/Co-occurrence)\n",
        "\n",
        "* [Distributional semantics](https://en.wikipedia.org/wiki/Distributional_semantics)\n",
        "\n",
        "* [Sparse distributed memory](https://en.wikipedia.org/wiki/Sparse_distributed_memory)\n",
        "\n",
        "* [Hamming distance](https://en.wikipedia.org/wiki/Hamming_distance)\n",
        "\n",
        "* [Information theory](https://en.wikipedia.org/wiki/Information_theory)\n",
        "\n",
        "* [Exponential distribution - Wikipedia](https://en.wikipedia.org/wiki/Exponential_distribution)\n",
        "\n",
        "\n",
        "\n",
        "* [Technical Perspective: Why Don't Today's Deep Nets Overfit to Their Training Data?](https://cacm.acm.org/magazines/2021/3/250716-technical-perspective-why-dont-todays-deep-nets-overfit-to-their-training-data/fulltext)\n",
        "\n",
        "* [Zooko's triangle](https://en.wikipedia.org/wiki/Zooko%27s_triangle)\n",
        "\n",
        "\n",
        "\n",
        "* [Never a dill moment: Exploiting machine learning pickle files](https://blog.trailofbits.com/2021/03/15/never-a-dill-moment-exploiting-machine-learning-pickle-files/)\n",
        "\n",
        "* [Density estimation](https://en.wikipedia.org/wiki/Density_estimation)\n",
        "\n",
        "* [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)\n",
        "\n",
        "* [* [Predictive Coding has been Unified with Backpropagation](https://www.lesswrong.com/posts/JZZENevaLzLLeC3zn/predictive-coding-has-been-unified-with-backpropagation)](https://wiki.c2.com/?HeroicProgramming)\n",
        "\n",
        "* [Language model](https://en.wikipedia.org/wiki/Language_model)"
      ]
    }
  ]
}