{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Nanodegree.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMUffvEe9caKAcAb/plAKjr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbremont/Notas/blob/main/Ingenerare/src/Deep_Learning_Nanodegree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2cW1QQuSUkl"
      },
      "source": [
        "# Deep Learning Nanodegree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3oMz8xUSWtw"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "**Prerequisites**\n",
        "\n",
        "We've designed this program such that you only require the following prerequisite knowledge:\n",
        "\n",
        "Required\n",
        "- Intermediate Python experience.\n",
        "\n",
        "**Optional**\n",
        "\n",
        "- Multivariable Calculus and Linear Algebra if possible.\n",
        "\n",
        "That being said, we've included a lot of the detailed mathematics for those of you who do want to go in depth and understand the theory behind these concepts. \n",
        "Such content is optional and shouldn't prevent you from doing the projects. \n",
        "\n",
        "However, **it is encouraged for a theoretical understanding**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GJcqSkAVrb0"
      },
      "source": [
        "Tools:\n",
        "\n",
        "- Anaconda, I'am going to use Jupyter alone,\n",
        "- Pandas,\n",
        "- Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-WUuJX-WqAH"
      },
      "source": [
        "#### Applying Deep Learning\n",
        "\n",
        "[Ir](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/06fec0e0-a78e-4ef9-b07d-29a92b4ae706/concepts/2c0a7702-083d-4983-bf85-78f44f8b9239)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR9PccL_VrWl"
      },
      "source": [
        "[**Style Transfer**](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/06fec0e0-a78e-4ef9-b07d-29a92b4ae706/concepts/83fb61aa-cf8f-4334-abb9-a8beb6e5beba)\n",
        "\n",
        "Demostración de tranferencias de estilos\n",
        "\n",
        "- Transfer :  (x) -> y\n",
        "\n",
        "- `python evaluate.py --checkpoint ./rain-princess.ckpt --in-path <path_to_input_file> --out-path ./output_image.jpg`\n",
        "\n",
        "[fast-style-transfer](https://github.com/lengstrom/fast-style-transfer)\n",
        "\n",
        "[Rain Princess checkpoint](https://d17h27t6h515a5.cloudfront.net/topher/2017/January/587d1865_rain-princess/rain-princess.ckpt)\n",
        "\n",
        "\n",
        "[**DeepTraffic**](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/06fec0e0-a78e-4ef9-b07d-29a92b4ae706/concepts/4a0a6357-30af-439b-9697-088427e6ddb8)\n",
        "\n",
        "[DeepTraffic Solution | MIT: Deep Learning for Self-Driving Cars](https://www.youtube.com/watch?v=JC-bI0baVv0)\n",
        "\n",
        "[Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning)\n",
        "\n",
        "[Deep Neural Networks for YouTube Recommendations](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45530.pdf)\n",
        "\n",
        "[**Flappy Bird**](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/06fec0e0-a78e-4ef9-b07d-29a92b4ae706/concepts/8a8c1d16-6261-4bbd-8a0c-6bc41e71e5d1)\n",
        "\n",
        "[DeepLearningFlappyBird](https://github.com/yenchenlin/DeepLearningFlappyBird)\n",
        "\n",
        "**Books**\n",
        "\n",
        "- [Grokking Deep Learning](https://colab.research.google.com/github/dbremont/Notas/blob/main/Libros/Aprendisaje%20Automatico/Grokking_Deep_Learning.ipynb)\n",
        "\n",
        "- [Neural Networks And Deep Learning](https://colab.research.google.com/github/dbremont/Notas/blob/main/Libros/Aprendisaje%20Automatico/Neural%20Networks%20and%20Deep%20Learning.ipynb)\n",
        "\n",
        "- [The Deep Learning Textbook](https://colab.research.google.com/github/dbremont/Notas/blob/main/Libros/Aprendisaje%20Automatico/Deep_Learning_Goodfellow,_Bengio_&_Courville.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlGq8Fmce9jL"
      },
      "source": [
        "#### Jupyter Notebooks\n",
        "[Ir](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/430aa4e8-23a7-4576-8651-1bf739f651da/concepts/f98abbc9-9260-43e4-9180-ae3b2e4f5cd9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziPNprevfDUP"
      },
      "source": [
        "**What are Jupyter notebooks?**\n",
        "\n",
        "[Ir](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/430aa4e8-23a7-4576-8651-1bf739f651da/concepts/4b44ef20-6f78-4a3b-9654-4ffb8593618f)\n",
        "\n",
        "For some notebooks go to:\n",
        "\n",
        "[Gravitational Wave Open Science Center](https://www.gw-openscience.org/tutorials/)\n",
        "\n",
        "You can create slides with nbconvert:\n",
        "\n",
        "`jupyter nbconvert notebook.ipynb --to slides --post serve`\n",
        "\n",
        "[Notebook Examples](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/examples_index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk-i6hqNivFy"
      },
      "source": [
        "#### Matrix Math and Numpy Refresher\n",
        "\n",
        "[Ir](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/4abae103-361f-4614-ab3c-7cc2a6758a0e/concepts/050b3d0d-34f5-4772-af2a-d2182634ac00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHSH4VDri1EA"
      },
      "source": [
        "![Matrix](https://video.udacity-data.com/topher/2017/January/58895788_input-times-weights/input-times-weights.png )\n",
        "\n",
        "Deep learning involves a lot of matrix math, and it’s important for you to understand the basics before diving into building your own neural networks. These lessons provide a short refresher on what you need to know for this course, along with some guidance for using the [NumPy](http://www.numpy.org/) library to work efficiently with matrices in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDxNI4Xff3do"
      },
      "source": [
        "**Data Dimensions**\n",
        "[Ir](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/4abae103-361f-4614-ab3c-7cc2a6758a0e/concepts/987e90aa-11a2-41c1-ae61-a52a1351158c)\n",
        "\n",
        "- How to map data to numbers, to be able manipulated in the computer.\n",
        "\n",
        "Dimensions:\n",
        " - Scalar, 0D,\n",
        " - Vectors (row vector, column vector) 1D,\n",
        " - Matrix 2D,\n",
        " - ... Tensor  (Tensor ND)\n",
        "\n",
        " Structure - Element is the structure\n",
        " - How to refer to elements in that structures, using an index. Recordar la etimologia del indice. (Lo que apunta a )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfC2YxXnwa_h"
      },
      "source": [
        "**Introducing NumPy**\n",
        "\n",
        "[Ir](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/4abae103-361f-4614-ab3c-7cc2a6758a0e/concepts/bc46810e-694d-4cfd-9cf5-ba4a90b5a413)\n",
        "\n",
        "`import numpy as np`\n",
        "\n",
        "**Data Types and Shapes**: The most common way to work with numbers in `NumPy` is through `ndarray` objects. They are similar to Python lists, but can have any number of dimensions. Also, `ndarray` supports fast math operations, which is just what we want.\n",
        "\n",
        "**Scalars**: uint8, int8, uint16, int16, and so on.\n",
        "\n",
        "**Vectors**: `np.array([1,2,3])`\n",
        "\n",
        "**Matrices**: You create using NumPy's `array` function, just you did for vectors. `np.array([[1,2,3], [4,5,6], [7,8,9]])`\n",
        "\n",
        "**Changing Shapes**: Sometimes you'll need to change the shape of your data without actually changing its contents. For example, you may have a vector, which is one-dimensional, but need a matrix, which is two-dimensional. There are two ways you can do that.\n",
        "\n",
        "```python\n",
        "v = np.array([1,2,3,4])\n",
        "\n",
        "#Calling v.shape would return (4,). But what if you want a 1x4 matrix? You can accomplish that with the reshape function, like so:\n",
        "\n",
        "x = v.reshape(1,4)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hREnjVyShoS7"
      },
      "source": [
        "[**Element-wise Matrix Operations**](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/4abae103-361f-4614-ab3c-7cc2a6758a0e/concepts/ec86588e-9ae7-4756-93eb-44ba401057e3)\n",
        "\n",
        "\n",
        "[More](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/4abae103-361f-4614-ab3c-7cc2a6758a0e/concepts/670574dc-6984-4231-9453-97fd2ba0a3ea)\n",
        "\n",
        "```python\n",
        "values = [1,2,3,4,5]\n",
        "values = np.array(values) + 5\n",
        "\n",
        "# now values is an ndarray that holds [6,7,8,9,10]\n",
        "```\n",
        "\n",
        "Element-wise Matrix Operations\n",
        "\n",
        "```python\n",
        "a = np.array([[1,3],[5,7]])\n",
        "a\n",
        "# displays the following result:\n",
        "# array([[1, 3],\n",
        "#        [5, 7]])\n",
        "\n",
        "b = np.array([[2,4],[6,8]])\n",
        "b\n",
        "# displays the following result:\n",
        "# array([[2, 4],\n",
        "#        [6, 8]])\n",
        "\n",
        "a + b\n",
        "# displays the following result\n",
        "#      array([[ 3,  7],\n",
        "#             [11, 15]])\n",
        "```\n",
        "\n",
        "[Matrix Multiplication](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/4abae103-361f-4614-ab3c-7cc2a6758a0e/concepts/835ed1ff-8970-42fc-af9d-14dfb7e7061c)\n",
        "\n",
        "Matrix multiplication is a series of dot products between rows and columns of two matrices.\n",
        "\n",
        "[More on Wikipedia](https://en.wikipedia.org/wiki/Matrix_multiplication)\n",
        "\n",
        "The number columns in the left matrix must be equal to the number of rows in the right matrix.\n",
        "\n",
        "- [matmul](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html#numpy.matmul)\n",
        "\n",
        "- [dot](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)\n",
        "\n",
        "[Transpose](https://classroom.udacity.com/nanodegrees/nd101/parts/38543a0e-e395-42fe-9b16-1c2fdd8a3bf4/modules/c3289945-9afb-4a5f-806b-25b96cc7ee4e/lessons/4abae103-361f-4614-ab3c-7cc2a6758a0e/concepts/129a471f-c105-401a-87bd-ccfae8d5941f) Getting the transpose of a matrix is really easy in NumPy. Simply access its T attribute. There is also a `transpose()` function which returns the same thing, but you’ll rarely see that used anywhere because typing `T` is so much easier. :)\n",
        "\n",
        "```python\n",
        "# Use the numpy library\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "######################################################\n",
        "#\n",
        "#      MESSAGE TO STUDENTS:\n",
        "#\n",
        "#  This file contains a solution to the coding quiz. Feel free\n",
        "#  to look at it when you are stuck, but try to solve the\n",
        "#   problem on your own first.\n",
        "#\n",
        "######################################################\n",
        "\n",
        "\n",
        "def prepare_inputs(inputs):\n",
        "    # TODO: create a 2-dimensional ndarray from the given 1-dimensional list;\n",
        "    #       assign it to input_array\n",
        "    input_array = np.array([inputs])\n",
        "    \n",
        "    # TODO: find the minimum value in input_array and subtract that\n",
        "    #       value from all the elements of input_array. Store the\n",
        "    #       result in inputs_minus_min\n",
        "    # We can use NumPy's min function and element-wise division\n",
        "    inputs_minus_min = input_array - np.min(input_array)\n",
        "\n",
        "    # TODO: find the maximum value in inputs_minus_min and divide\n",
        "    #       all of the values in inputs_minus_min by the maximum value.\n",
        "    #       Store the results in inputs_div_max.\n",
        "    # We can use NumPy's max function and element-wise division\n",
        "    inputs_div_max = inputs_minus_min / np.max(inputs_minus_min)\n",
        "\n",
        "    return input_array, inputs_minus_min, inputs_div_max\n",
        "    \n",
        "\n",
        "def multiply_inputs(m1, m2):\n",
        "    # Check the shapes of the matrices m1 and m2. \n",
        "    # m1 and m2 will be ndarray objects.\n",
        "    #\n",
        "    # Return False if the shapes cannot be used for matrix\n",
        "    # multiplication. You may not use a transpose\n",
        "    if m1.shape[0] != m2.shape[1] and m1.shape[1] != m2.shape[0]:     \n",
        "        return False\n",
        "\n",
        "    # Have not returned False, so calculate the matrix product\n",
        "    # of m1 and m2 and return it. Do not use a transpose,\n",
        "    #       but you swap their order if necessary\n",
        "    if m1.shape[1] == m2.shape[0]:\n",
        "        return np.matmul(m1, m2)        \n",
        "    else:\n",
        "        return np.matmul(m2, m1)        \n",
        "\n",
        "\n",
        "def find_mean(values):\n",
        "    # Return the average of the values in the given Python list\n",
        "    # NumPy has a lot of helpful methods like this.\n",
        "    return np.mean(values)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB5RbS8lSY1K"
      },
      "source": [
        "## Neural Networks\n",
        "\n",
        "**Predicting Bike-Sharing Data**\n",
        "\n",
        "In this part, you'll learn how to build a simple neural network from scratch using python. We'll cover the algorithms used to train networks such as gradient descent and backpropagation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx6GAC9J4R6Q"
      },
      "source": [
        "### Introduction to Neural Networks\n",
        "[Ir](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/18a1bec3-4ad2-4293-9541-e1354f0e1517)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSLrEd8K9aHX"
      },
      "source": [
        "[**Introduction**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/bfeee263-acd3-47b0-9f0f-887a321ce235)\n",
        "\n",
        "- How clasification relates with regression?\n",
        "\n",
        "- In this lesson we will tackle the classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNa2sWU_hrY"
      },
      "source": [
        "[**Linear Boundaries**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/7910f36b-9747-42a4-898b-95a83ac15e23)\n",
        "\n",
        "Given a linear equation to separete a plane, with data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7asZy5tLAueW"
      },
      "source": [
        "[**Higher Dimensions**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/12905746-f8ff-44ae-b496-7552a3bbb303)\n",
        "\n",
        "n-dimensional space \n",
        "\n",
        "$x_1, x_2, ..., x_3$\n",
        "\n",
        "Boundarie:\n",
        "\n",
        "n-1 dimensional hyperplane\n",
        "\n",
        "$w_1x_1  + w_2x_2 + w_nx_n + b$ = 0\n",
        "\n",
        "\n",
        "Prediction\n",
        "\n",
        "\\begin{equation*}\n",
        "\\hat{y} =  \\left\\{\n",
        "        \\begin{array}{ll}\n",
        "           1 & \\quad Wx + b \\geq 0 \\\\\n",
        "           0 & \\quad Wx + b \\leq 0\n",
        "        \\end{array}\n",
        "    \\right.\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWsAyfgmFagJ"
      },
      "source": [
        "[**Perceptron**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/cdf0bedb-e854-426d-82d6-fab3724e7d3d)\n",
        "\n",
        "![Perceptron](https://miro.medium.com/max/1838/1*n6sJ4yZQzwKL9wnF5wnVNg.png)\n",
        "\n",
        "[How to Get the Most Out of Towards Data Science](https://towardsdatascience.com/how-to-get-the-most-out-of-towards-data-science-3bf37f75a345)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YeiyslGIj2G"
      },
      "source": [
        "[**Perceptrons as Logical Operators**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/3e950ae2-ed97-43d6-b0a6-a614f2962bc5)\n",
        "\n",
        "[Representing the AND as a perceptron](https://youtu.be/Y-ImuxNpS40)\n",
        "\n",
        "What are the weights and bias for the AND perceptron?\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# TODO: Set weight1, weight2, and bias\n",
        "weight1 = 0.1\n",
        "weight2 = 0.1\n",
        "bias = -0.2\n",
        "\n",
        "\n",
        "# DON'T CHANGE ANYTHING BELOW\n",
        "# Inputs and outputs\n",
        "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "correct_outputs = [False, False, False, True]\n",
        "outputs = []\n",
        "\n",
        "# Generate and check output\n",
        "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
        "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
        "    output = int(linear_combination >= 0)\n",
        "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
        "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
        "\n",
        "# Print output\n",
        "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
        "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
        "if not num_wrong:\n",
        "    print('Nice!  You got it all correct.\\n')\n",
        "else:\n",
        "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
        "print(output_frame.to_string(index=False))\n",
        "\n",
        "```\n",
        "\n",
        "What are two ways to go from an AND perceptron to an OR perceptron?\n",
        "\n",
        "- Increase the weiths $\\checkmark$\n",
        "- Decrease the weights\n",
        "- Increase a single weight\n",
        "- Decrease a single weight\n",
        "- Increase the magnitude of the bias\n",
        "- Decrease the magnitude of the bias $\\checkmark$\n",
        "\n",
        "[XOR Perceptron](https://youtu.be/-z9K49fdE3g)\n",
        "\n",
        "Build an XOR Multi-Layer Perceptron\n",
        "\n",
        "![Imagen](https://d17h27t6h515a5.cloudfront.net/topher/2017/May/59112cdf_xor-quiz2/xor-quiz2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdU0aZ0LMFjd"
      },
      "source": [
        "[**Percepton Trick**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/290788e8-1ba0-4839-9c92-450802a5bf0d)\n",
        "\n",
        "Given an initial graph, and a set of points\n",
        "- The miss clasified points will like the graph become closer to them, so they get classified correctly\n",
        "\n",
        "How to modified the equatiosn to move the line closer to the misclassified points?\n",
        "\n",
        "[The Math](https://youtu.be/lif_qPmXvWA)\n",
        "\n",
        "[Learning Rate](https://en.wikipedia.org/wiki/Learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qVh_I4SoW00"
      },
      "source": [
        "[**Perceptron Algorithm**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/afc3884a-9292-4ae3-8607-bf596078fc3a)\n",
        "\n",
        "1. Start with random weights: $w_1, ..., w_n, b$\n",
        "2. For Every mis-classified point (x_1, ..., x_n)\n",
        "  \n",
        "  2.1. If `prediction  = 0`:\n",
        "  - For i = 1 ...n\n",
        "    - Change $w_i  + \\alpha x_i$\n",
        "  - Change $b = b + \\alpha$\n",
        "\n",
        "  2.2 If `prediction  =1`:\n",
        "  - For i = 1 ... n\n",
        "    - Change $w_i - \\alpha x_i$\n",
        "    - Change $b  = b - \\alpha$\n",
        "\n",
        "Recall that the perceptron step works as follows. For a point with coordinates $(p,q)$, label $y$, and prediction given by the equation $\\hat{y} = step(w_1x_1 + w_2x_2 + b)$\n",
        "- If the point is correctly classified, do nothing.\n",
        "\n",
        "- If the point is classified positive, but has a negative label, subtract $\\alpha p$, $\\alpha q$, and $\\alpha$ from $w_1, w_2$, and $b$ respectively.\n",
        "\n",
        "- If the point is classified negative, but it has a positive labe, add $\\alpha p$, $\\alpha q$, and $\\alpha$ to $w_1, w_2$, and $b$ respectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wek_be75SF0y"
      },
      "source": [
        "```python\n",
        "\n",
        "# https://raw.githubusercontent.com/dbremont/Notas/main/Data/perceptron_data.csv\n",
        "\n",
        "# Preceptron Algorithm\n",
        "\n",
        "import numpy as np\n",
        "# Setting the random seed, feel free to change it and see different solutions.\n",
        "np.random.seed(42)\n",
        "\n",
        "def stepFunction(t):\n",
        "    if t >= 0:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def prediction(X, W, b):\n",
        "    return stepFunction((np.matmul(X,W)+b)[0])\n",
        "\n",
        "# TODO: Fill in the code below to implement the perceptron trick.\n",
        "# The function should receive as inputs the data X, the labels y,\n",
        "# the weights W (as an array), and the bias b,\n",
        "# update the weights and bias W, b, according to the perceptron algorithm,\n",
        "# and return W and b.\n",
        "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
        "    for i in range(len(X)):\n",
        "        y_hat = prediction(X[i],W,b)\n",
        "        if y[i]-y_hat == 1:\n",
        "            W[0] += X[i][0]*learn_rate\n",
        "            W[1] += X[i][1]*learn_rate\n",
        "            b += learn_rate\n",
        "        elif y[i]-y_hat == -1:\n",
        "            W[0] -= X[i][0]*learn_rate\n",
        "            W[1] -= X[i][1]*learn_rate\n",
        "            b -= learn_rate\n",
        "    return W, b\n",
        "\n",
        "    \n",
        "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
        "# and returns a few of the boundary lines obtained in the iterations,\n",
        "# for plotting purposes.\n",
        "# Feel free to play with the learning rate and the num_epochs,\n",
        "# and see your results plotted below.\n",
        "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
        "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
        "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
        "    W = np.array(np.random.rand(2,1))\n",
        "    b = np.random.rand(1)[0] + x_max\n",
        "    # These are the solution lines that get plotted below.\n",
        "    boundary_lines = []\n",
        "    for i in range(num_epochs):\n",
        "        # In each epoch, we apply the perceptron step.\n",
        "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
        "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
        "    return boundary_lines\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SoU_dcQTxc-"
      },
      "source": [
        "[**Error Functions**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/81ded40e-a27b-4b78-9c5e-5090aefeef86)\n",
        "\n",
        "- How far I am from a solution "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqwCs-jNT70V"
      },
      "source": [
        "[**Log-loss Error Function**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/ef400f37-e1a7-486e-9296-1fff09949484)\n",
        "\n",
        "We pick back up on log-loss error with the gradient descent concept.\n",
        "\n",
        "Which of the following conditions should be met in order to apply gradient descent? (Check all that apply.)\n",
        "\n",
        "- The error function should be discrete\n",
        "- The error function should contain only positive values\n",
        "- The error function should be differentiable\n",
        "- The error function should be normalized\n",
        "- The error function should be continuous\n",
        "\n",
        "- Given an error function, we would like to minimize the error function.\n",
        "- We use gradient descent to do this, and calculus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBuoaPX9XjEh"
      },
      "source": [
        "[**Discrete vs Continuous Predictions**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/aa62b8e2-4b19-4085-ba58-f2285573c52e)\n",
        "\n",
        "Continuous error functions are better than discrete error functions, when it comes to optimizing. For this, we need to switch from discrete to continuous predictions.\n",
        "\n",
        "- The sigmoid step function for clasification, in the perceptron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfBfPb6IYoke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da43be54-3a43-4971-f176-7e72a810eb02"
      },
      "source": [
        "'''\n",
        "The sigmoid function is defined as sigmoid(x) = 1/(1+e-x).\n",
        "If the score is defined by 4x1 + 5x2 - 9 = score, \n",
        "then which of the following points has exactly a 50% probability of being blue or red? (Choose all that are correct.)\n",
        "'''\n",
        "\n",
        "import math\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def score(x, y):\n",
        "  return x*4 + y*5 - 9\n",
        "\n",
        "points  = [(1,1), (2,4), (5,-5), (-4,5)]\n",
        "\n",
        "for point in points:\n",
        "  x, y = point\n",
        "  print(point, sigmoid(score(x, y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1) 0.5\n",
            "(2, 4) 0.9999999943972036\n",
            "(5, -5) 8.315280276641321e-07\n",
            "(-4, 5) 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2-LWUYnaJK5"
      },
      "source": [
        "[**Multi-Class Classification and Softmax**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/0cf851b3-7e0d-41f5-a845-97a629c4e9f2)\n",
        "\n",
        "So far we have models that gives us yes/no answers, but what if you need a model that tell us more then two answers.\n",
        "\n",
        "**The Softmax Function**\n",
        "\n",
        "- The softwax is a step function.\n",
        "\n",
        "Let say we have $n$ clases, and $Z_1, ..., Z_n$ score functions for each of the classes, $\\frac{P(\\text{class}_i ) = e^z_i} {e^z_1 + ... + e^z_n}$\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Write a function that takes as input a list of numbers, and returns\n",
        "# the list of values given by the softmax function.\n",
        "def softmax(L):\n",
        "    expL = np.exp(L)\n",
        "    suma = expL.sum()\n",
        "    result =   [i*1.0/suma  for i in expL]\n",
        "    return result\n",
        "    \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lHxe0RIn__i"
      },
      "source": [
        "[**One-Hot Encoding**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/20ea0757-8d71-4067-b668-6513e6cd6a72)\n",
        "\n",
        "- Convert non-numeric values to numeric values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68lO4krIqYY9"
      },
      "source": [
        "[**Maximum Likelihood**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/f885c498-3540-407b-af96-6f2340cded92)\n",
        "\n",
        "- Pick the model that make better preditions.\n",
        "- Maximize the probability of getting it right.\n",
        "\n",
        "[Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)\n",
        "\n",
        "[Probability concepts explained: Maximum likelihood estimation](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)\n",
        "\n",
        "[Maximum Likelihood, clearly explained!!!](https://www.youtube.com/watch?v=XepXtl9YKwc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5hlJIJHtsNg"
      },
      "source": [
        "[**Maximizing Probabilities**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/51870495-6722-4837-9df6-7b985a645d40)\n",
        "\n",
        "\n",
        "\n",
        "What function turns products into sums?\n",
        "\n",
        "- sin,\n",
        "- cos,\n",
        "- log,\n",
        "- exp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUGn__BtvOQK"
      },
      "source": [
        "**Cross Entropy**\n",
        "\n",
        "[Part 1](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/c58b2b46-1c54-450f-b97d-a32b4acb5c03)\n",
        "\n",
        "[Part 2](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/36bceb55-72e8-4610-beca-3ca0b24ab6e0)\n",
        "\n",
        "If i have a bunch of events and a bunch of probabilities, how likely is that those events happends based on the probabilities?\n",
        "\n",
        "- If it's very likely, then we have a small scross entropty,\n",
        "- If it's unlikely, then we have a large cross entropy\n",
        "\n",
        "[What is entropy? - Jeff Phillips][(https://www.youtube.com/watch?v=YM-uykVfq_E)]\n",
        "\n",
        "[Entropy (for data science) Clearly Explained!!!](https://www.youtube.com/watch?v=YtebGVx-Fxw)\n",
        "\n",
        "[The Biggest Ideas in the Universe | 20. Entropy and Information](https://www.youtube.com/watch?v=rBPPOI5UIe0)\n",
        "\n",
        "[Cross entropy](https://en.wikipedia.org/wiki/Cross_entropy)\n",
        "\n",
        "- -In(Probability) is the entropy\n",
        "- Cross-Entropy $-\\sum_{i=1}^{m} y_iln(p_i) + (1-y_i)ln(1-p_i)$\n",
        "\n",
        " Cross-entropy is inversely proportional to the total probability of an outcome.\n",
        "\n",
        "```\n",
        "# Cross Entropy Python Formula\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Write a function that takes as input two lists Y, P,\n",
        "# and returns the float corresponding to their cross-entropy.\n",
        "def cross_entropy(Y, P):\n",
        "    Ynp =  np.array(Y)\n",
        "    Pnp =  np.array(P)\n",
        "    return -1 * (Ynp.dot(np.log(Pnp)) + (1 - Ynp).dot( np.log(1 - Pnp)))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpiXUf9wf8qp"
      },
      "source": [
        "[**Multiclass-Cross Entropy**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/9cb94bee-5a2d-4c4b-9619-2418821017a2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QrLRcblgU92"
      },
      "source": [
        "[**Logistic Regression**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/8b779028-0a11-483e-ad7f-91e89f495c8e)\n",
        "\n",
        "The **Logistic Regression** Algorithm. And it basically goes like this:\n",
        "\n",
        "- Take your data\n",
        "- Pick a random model\n",
        "- Calculate the error\n",
        "- Minimize the error, and obtain a better model\n",
        "- Enjoy!\n",
        "\n",
        "Calculating the Error Function\n",
        "\n",
        "- A model is better than other becuase of the cross-entropy.\n",
        "\n",
        "[Logistic regression multiclass classification | Cross Entropy Loss and optimization | SoftMax](https://www.youtube.com/watch?v=el8-0yWA3lk)\n",
        "\n",
        "[Softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
        "\n",
        "[A Gentle Introduction to Cross-Entropy for Machine Learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)\n",
        "\n",
        "[Log Loss or Cross-Entropy Cost Function in Logistic Regression](https://www.youtube.com/watch?v=MztgenIfGgM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYXlALBflHBP"
      },
      "source": [
        "[**Gradient Descent**](https://classroom.udacity.com/nanodegrees/nd101/parts/9816d583-e769-499b-9d80-939bb4dcf391/modules/505e9cd2-f4c9-49f4-8f45-abbad51134a8/lessons/90cf08f6-dede-4b37-b54f-7cb42b882cc4/concepts/ae77d35a-3d1d-47a0-993d-6593486eb3da)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD_knm-1Saix"
      },
      "source": [
        "## Convolutional Networks\n",
        "\n",
        "**Dog Breed Classifier**\n",
        "\n",
        "Convolutional networks have achieved state of the art results in computer vision. These types of networks can detect and identify objects in images. You'll learn how to build convolutional networks in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmLeBE2iSffp"
      },
      "source": [
        "## Recurrent Neural Networks\n",
        "\n",
        "**Generate TV Scripts**\n",
        "\n",
        "In this part, you’ll learn about Recurrent Neural Networks (RNNs) — a type of network architecture particularly well suited to data that forms sequences like text, music, and time series data. You'll build a recurrent neural network that can generate new text character by character."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8c6T6pMShUz"
      },
      "source": [
        "## Generative Adversarial Networks\n",
        "\n",
        "**Generate Faces**\n",
        "\n",
        "Generative adversarial networks (GANs) are one of the newest and most exciting deep learning architectures, showing incredible capacity for understanding real-world data. In this part, you'll learn about and implement GANs for a variety of tasks. You'll even see how to code a CycleGAN for generating images, and learn from one of the creators of this formulation, Jun-Yan Zhu, a researcher at MIT's CSAIL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTFRgKVOSi_z"
      },
      "source": [
        "## Deploying Machine Learning Models\n",
        "\n",
        "**Deploy a Sentiment Analysis Model**\n",
        "\n",
        "As more and more companies look to build AI products, there is a growing demand for engineers who are able to deploy machine learning models to global audiences. In this part, you’ll get experience deploying a model so that it can be accessed via a web app and respond to user input."
      ]
    }
  ]
}