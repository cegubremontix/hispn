{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Databases.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbremont/Notas/blob/main/Ingenerare/Databases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UfxKH0p06kn"
      },
      "source": [
        "- SQL Lite Source Code\n",
        "  - Build & Debug\n",
        "- Virtual Machines\n",
        "- Parser\n",
        "- B-Tree ...\n",
        "- Para instalar SQLite hay que primero instalar tlc\n",
        "- Para ma;na tratar de ./configure && make en folder correctamente y ejecutar la shell y crear una tabla simple.\n",
        "\n",
        "----\n",
        "\n",
        "- Hacer fork a Simple DB MIT y verificar el codigo.\n",
        "- Cuantas clases hay,\n",
        "- Cuantas lineas de codigo hay.\n",
        "- Cuantos comentario hay.\n",
        "- Cuantas interfaces hay.\n",
        "- Cuantas enum hay.\n",
        "\n",
        "- Puedo compilarlo y generar el jar.\n",
        "- Puedo usar el jar?\n",
        "\n",
        "- Resumen de Terminologia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxDX6EDDUgDP"
      },
      "source": [
        "## Primario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXsvqYHwUqsk"
      },
      "source": [
        "\n",
        "* [15-445/645 Introduction to Database Systems](https://15445.courses.cs.cmu.edu/fall2019/)\n",
        "\n",
        "* [15-721 Advanced Database Systems](https://15721.courses.cs.cmu.edu/spring2020/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O48QM3g-UhGI"
      },
      "source": [
        "## Secundario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elz31sjbpwAe"
      },
      "source": [
        "* [CS6530: Graduate-level Database System](https://www.cs.utah.edu/~lifeifei/cs6530/)\n",
        "\n",
        "* [Database Systems](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-830-database-systems-fall-2010/)\n",
        "\n",
        "* [CS 276 / LING 286: Information Retrieval and Web Search](http://web.stanford.edu/class/cs276/)\n",
        "\n",
        "* [6.830/6.814: Database Systems](http://dsg.csail.mit.edu/6.830/index.php) \n",
        "\n",
        "* [6.033 Computer System Engineering](http://web.mit.edu/6.033/www/index.shtml)\n",
        "\n",
        "* [A Celebration of Mike Stonebraker](https://www.youtube.com/playlist?list=PLSE8ODhjZXjZO802SjzqBFFlkuKglgbZD)\n",
        "\n",
        "* [How To Compile SQLite](https://sqlite.org/howtocompile.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ_5CCKlLfGp"
      },
      "source": [
        "- Relational Databases\n",
        "- Storage\n",
        "- Execution\n",
        "- Concurrency Control\n",
        "- Recovery\n",
        "- Distributed Databases\n",
        "- Potpourri\n",
        "\n",
        "BusTub\n",
        "\n",
        "- Disk-based Storage,\n",
        "- Volcano-style Query Processing,\n",
        "- Pluggable APIs\n",
        "- Currently does not support SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2xrdZmTT8EU"
      },
      "source": [
        "## Query Plans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy9vRhUnbJdn"
      },
      "source": [
        "Join Algorithms:\n",
        "\n",
        "- [Join (SQL)](https://en.wikipedia.org/wiki/Join_(SQL))\n",
        "- [Hash join](https://en.wikipedia.org/wiki/Hash_join)\n",
        "- [Query plan](https://en.wikipedia.org/wiki/Query_plan)\n",
        "\n",
        "\n",
        "- Los planes en oracle se leen de abajo /  ariva.\n",
        "- Cuándo un plan es mejor que otro?\n",
        "- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykq5D9maloqk"
      },
      "source": [
        "### Understanding the execution plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPFZbpY_loqt"
      },
      "source": [
        "\n",
        "- **Cardinality**– Estimate of the number of rows coming out of each of the operations.\n",
        "\n",
        "- **Access method** – The way in which the data is being accessed, via either a table scan or index access.\n",
        "\n",
        "- **Join method** – The method (e.g., hash, sort-merge, etc.) used to join tables with each other.\n",
        "\n",
        "- **Join type** – The type of join (e.g., outer, anti, semi, etc.).\n",
        "\n",
        "- **Join order** – The order in which the tables are joined to each other.\n",
        "\n",
        "- **Partition pruning** – Are only the necessary partitions being accessed to answer the query?\n",
        "\n",
        "- **Parallel Execution** – In case of parallel execution, is each operation in the plan being conducted in parallel? Is the right data redistribution method being used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv8Okq04e-RX"
      },
      "source": [
        "### Access Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGO-kayEfAbI"
      },
      "source": [
        "The access method - or access path - shows how the data will be accessed from each table (or index). The access method  is shown in the operation field of the explain plan.\n",
        "\n",
        "Oracle supports nine common access methods:\n",
        "\n",
        "- **Full table scan :** Reads all rows from a table and filters out those that do not meet the where clause predictates. A full table scan will us muti block IO (typically 1MB IOs). A full table scan is selected if a large portion of the rows in the table must be acessed, no indexes exist or the ones present can't be used or if the cost is the lowest. The decision to use a full table scan is also influenced by the following:\n",
        "\n",
        "  - Init.ora parameter db_multi_block_read_count\n",
        "  - Parallel degree\n",
        "  - Hints\n",
        "  - Lack of useable indexes\n",
        "  - Using an index cost more\n",
        "\n",
        "- **Table access by ROWID:** The rowid of a row specifies the data file, the data block within that file, and the location of the row within that block. Oracle first obtains the rowids either from a *WHERE* clause predicate or through an index scan of one or more of the table's indexes. Oracle then locates each selected row in the table based on its *rowid* an does row-by-row access.\n",
        "\n",
        "- **Index unique scan** - Only one row will e rturned from he scan of a unique index. It will be used when there is an equiality predictate on a unique (B-tree) index or an index create as a result of a primary key constraint.\n",
        "\n",
        "- **Index range scan** – Oracle accesses adjacent index entries and then uses the ROWID values in the index to retrieve the corresponding rows from the table. An index range scan can be bounded or unbounded. It will be used when a statement has an equality predicate on a non-unique index key, or a non-equality or range predicate on a unique index key. (=, <, >,LIKE if not on leading edge). Data is returned in the ascending order of index columns.\n",
        "\n",
        "- **Index range scan descending** – Conceptually the same access as an index range scan, but it is used when an ```ORDER BY .. DESCENDING``` clause can be satisfied by an index.\n",
        "\n",
        "- **Index skip scan** - Normally, in order for an index to be used, the prefix of the index key (leading edge of the index) would be referenced in the query. However, if all the other columns in the index are referenced in the statement except the first column, Oracle can do an index skip scan, to skip the first column of the index and use the rest of it. This can be advantageous if there are few distinct values in the leading column of a concatenated index and many distinct values in the non-leading key of the index.\n",
        "\n",
        "- Full Index scan - A full index scan does not read every block in the index structure, contrary to what its name suggests. An index full scan processes all of the leaf blocks of an index, but only enough of the branch blocks to find the first leaf block. It is used when all of the columns necessary to satisfy the statement are in the index and it is\n",
        "cheaper than scanning the table. It uses single block IOs. It may be used in any of the following situations:\n",
        "\n",
        "  -  An *ORDER BY* clause has all of the index columns in it and the order is the same as in the index (can also contain a subset of the columns in the index).\n",
        "  \n",
        "  - The query requires a sort merge join and all of the columns referenced in the query are in the index.\n",
        "  \n",
        "  -  Order of the columns referenced in the query matches the order of the leading index columns.\n",
        "\n",
        "  - A *GROUP BY* clause is present in the query, and the columns in the *GROUP BY* clause are present in the index. \n",
        "\n",
        "- **Fast full index scan** - This is an alternative to a full table scan when the index contains all the columns that are needed for the query, and at least one column in the index key has the NOT NULL constraint. It cannot be used to eliminate a sort operation, because the data access does not follow the index key. It will also read all of the blocks in\n",
        "the index using multiblock reads, unlike a full index scan.\n",
        "\n",
        "- **Index join** – This is a join of several indexes on the same table that collectively contain all of the columns that are referenced in the query from that table. If an index join is used, then no table access is needed, because all the relevant column values can be retrieved from the joined indexes. An index join cannot be used to eliminate a sort\n",
        "operation\n",
        "\n",
        "- **Bitmap Index** – A bitmap index uses a set of bits for each key values and a mapping function that converts each bit position to a rowid. Oracle can efficiently merge bitmap indexes that correspond to several predicates in a ```WHERE``` clause, using Boolean operations to resolve ```AND``` and ```OR``` conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGscOHGwiorH"
      },
      "source": [
        "### Join Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_RMwbdZiqTI"
      },
      "source": [
        "The join method describes how data from two data producing operators will be joined together. You can identify the join methods used in a SQL statement by looking in the operations column in the explain plan. \n",
        "\n",
        "**Hash Joins** - Hash joins are used for joining large data sets. The optimizer uses the smaller of the two tables or data sources to build a hash table, based on the join key, in memory. It then scans the larger table, and performs the same hashing algorithm on the join column(s). It then probes the previously built hash table for each value and if they match, it returns a row.\n",
        "\n",
        "**Nested Loops joins** - Nested loops joins are useful when small subsets of data are being joined and if there is an efficient way of accessing the second table (for example an index look up). For every row in the first table (the outer table), Oracle accesses all the rows in the second table (the inner table). Consider it like two embedded FOR loops. In Oracle Database 11g the internal implementation for nested loop joins changed to reduce overall latency for physical I/O so it is possible you will see two ```NESTED LOOPS``` joins in the operations column of the plan, where you previously only saw one on earlier versions of Oracle\n",
        "\n",
        "**Sort Merge joins** – Sort merge joins are useful when the join condition between two tables is an in-equality condition such as, <, <=, >, or >=. Sort merge joins can perform better than nested loop joins for large data sets. The join consists of two steps:\n",
        "\n",
        "- Sort join operation: Both the inputs are sorted on the join key.\n",
        "\n",
        "- Merge join operation: The sorted lists are merged together.\n",
        "\n",
        "**Cartesian join** - The optimizer joins every row from one data source with every row from the other data source, creating a Cartesian product of the two sets. Typically this is only chosen if the tables involved are small or if one or more of the tables does not have a join conditions to any other table in the statement. Cartesian joins are not\n",
        "common, so it can be a sign of problem with the cardinality estimates, if it is selected for any other reason. Strictly speaking, a Cartesian product is not a join."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOKzurdQjga8"
      },
      "source": [
        "### Join Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9oS7EMIjiuW"
      },
      "source": [
        "Oracle offers several join types: inner join, (left) outer join, full outerjoin, anti join, semi join, grouped outer join, etc. Note that inner join is the most common type of join; hence the execution plan does not specify the key word “INNER’\n",
        "\n",
        "**Outer Join** - An outer join returns all rows that satisfy the join condition and also all of the rows from the table without the (+) for which no rows from the other table satisfy the join condition. For example, $T1.x = T2.x (+)$, here T1 is the left table whose non-joining rows will be retained. In the ANSI outer join syntax, it is the leading table whose non-join rows will be retained. The same example can be written in ANSI SQL as $T1$ ```LEFT OUTER JOIN``` $T2$ ON $(T1.x = T2.x)$;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQj6jxtPkLhk"
      },
      "source": [
        "### Join Order"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5uZpLtakNSE"
      },
      "source": [
        "The join order is the order in which the tables are joined together in a multi-table SQL statement. To determine the join order in an execution plan look at the indentation of the tables in the operation column. In Figure 22 below the ```SALES``` and ```PRODUCTS``` table are equally indented and both of them are more indented than the ```CUSTOMERS``` table. Therefore the ```SALES``` and ```PRODUCTS``` table will be joined first using a hash join and the result of that join will then be\n",
        "joined to the ```CUSTOMERS``` table.\n",
        "\n",
        "The join order is determined based on cost, which is strongly influenced by the cardinality estimates and the access paths available. The Optimizer will also always adhere to some basic rules:\n",
        "\n",
        "- Joins that result in at most one row always go first. The Optimizer can determine this based on UNIQUE and PRIMARY KEY constraints on the tables.\n",
        "\n",
        "- When outer joins are used the row preserving table (table without the outer join operator) must come after the other table in the predicate (table with the outer join operator) to ensure all of the additional rows that don’t satisfy the join condition can be added to the result set correctly.\n",
        "\n",
        "- When a subquery has been converted into an antijoin or semijoin, the tables from the subquery must come after those tables in the outer query block to which they were connected or correlated. However, hash antijoins and semijoins are able to override this ordering condition under certain circumstances.\n",
        "\n",
        "- If view merging is not possible all tables in the view will be joined before joining to the tables outside the view.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztUSSA4rlDS1"
      },
      "source": [
        "### Partitioning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYaK07nrlEZz"
      },
      "source": [
        "Partitioning allows a table, index or  index-organized table to be subdivided into smaller pieces. Each piece of the database object is called a Partition. Partition pruning or Partition elimination is the simplest means to improve\n",
        "performance using Partitioning. For example, if an application has an ```ORDERS``` table that contains a record of all orders for the last 2 years, and this table has been partitioned by day, a query requesting orders for a single week would only access seven partitions of the ```ORDERS``` table instead of 730 partitions (the entire table).\n",
        "\n",
        "Partition pruning is visible in an execution plan in the ```PSTART``` and ```PSTOP``` columns. The ```PSTART``` column contains the number of the first partition that will be accessed and PSTOP column contains the number of the last partition that will be accessed1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1yVIh_3bJXX"
      },
      "source": [
        "## 01 Relational Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5OhwdYHM28e"
      },
      "source": [
        "**Database**: Organized collection of inter-related data that models some aspect of the real-world.\n",
        "\n",
        "- Ej. Create a database that models a diginal music store to keep track of artists and albumns.\n",
        "\n",
        "**Database Management System**: Is a software system that allows applications to store and analyze information in a database.  \n",
        "\n",
        "A general-purpose DBMS is designed to allow the definition, creation, querying, update, and administration of databases.\n",
        "\n",
        "Database abstraction to avoid this\n",
        "maintenance:\n",
        "-  Store database in simple data structures.\n",
        "- Access data through high-level language,\n",
        "DBMS figures out best strategy.\n",
        "-  Physical storage left up to the DBMS\n",
        "implementation.\n",
        "\n",
        "Data Models\n",
        "\n",
        "- A data model is a collection of concepts for\n",
        "describing the data in a database.\n",
        "  - Relational,\n",
        "  - Key/Value,\n",
        "  - Graph,\n",
        "  - Document,\n",
        "  - Column-family,\n",
        "  - Array/Matrix,\n",
        "  - Hierarchical,\n",
        "  - Network,\n",
        "  - Multi-Value\n",
        "\n",
        "- A schema is a description of a particular collection\n",
        "of data, using a given data model.\n",
        "\n",
        "Relational Data Model\n",
        "\n",
        "- **Structure**: The Definition of the database's relations and their contents.\n",
        "- **Integrity**: Ensure the database's contents sastify constrains.\n",
        "- **Manipulation**: Programming interface for accesing and modifying a database's contents.\n",
        "\n",
        "### Relational Data Model Concepts\n",
        "\n",
        "- A Relation: is an unordered set that contain the relationship of attributes that represents entities.\n",
        "- A tuple: is a set of attribute values (also kknown as its domain) in the relation.\n",
        " - Values are (normally) atomic/scalar.\n",
        " - The special value NULL is a member of every domain.\n",
        "\n",
        "Primary Keys: A relation's primary keys uniquely identifies a single tuple.\n",
        "- Some DBMSs automatically create an internal primary key if a table does not defined one.\n",
        "- Auto-generation of unique integer primary keys:\n",
        "  - Sequence (sql:2003)\n",
        "  - Auto_Increment (MySQL)\n",
        "\n",
        "Foreign Keys:\n",
        "- A *foreign key* specifies that an attribute from one relation has to map to a tuple in another relation.\n",
        "\n",
        "Data Manipulation Languages (DML)\n",
        "\n",
        "- Methods to store and retrieve information from a database.\n",
        "- Procedural: The query specifites the (high-level) strategy the DBMS should use to find the desired result. (Relational Algebra)\n",
        "- Non-Procedural: The query specifies only what data is wanted and not how to find it. (Relational Calculus)\n",
        "\n",
        "Relational Algebra:\n",
        "\n",
        "- **Note**: Relational algebra still defines the high-level steps of how to compute a query. A better approach is to state the high-level answer that you want  the DBMS to compute.\n",
        "\n",
        "- Defines the primitives for processing queries on a relational database.\n",
        "\n",
        "- Fundamental operations that retrieve and manipulate tuples in a relation.\n",
        "- Each *operator* takes one or more relation as its inputs and ouputs a new relation. \"We can 'chain' operators together to create  more complex operations\".\n",
        "\n",
        "\n",
        "- Select: Choose a subset of tuples from a relation that sastisfies a selection predicate.\n",
        "- Projection: Generate a relation with tuples that contains only the specifies attributes.\n",
        "- Union: Generate a relation that constains all tuples that appear in either only one or both input relations.\n",
        "- Intersection: Generate a relation that contains only the tuples that appear in both of the input relations.\n",
        "- Difference: Generate a relation that contains only the tuples \n",
        "- Product: Generate a relation that contains all possible combinations of tuples from the input relations.\n",
        "- Join: Generate a relation that contains all tuples that are combination of two tuples(one from each input relation)  which a commmon value(s) from one or more attributes.\n",
        "\n",
        "\n",
        "Extra Operators:\n",
        " - Rename,\n",
        " - Assign,\n",
        " - Duplicate Elimination,\n",
        " - Aggregation,\n",
        " - Sorting,\n",
        " - Division\n",
        "\n",
        "Queries:\n",
        "- The relational model is independent of any query language   implementation. \n",
        "- *SQL* is the *de fato* standard (many dialects)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86qLZZrtghpH"
      },
      "source": [
        "## 02 Intermediate SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbugH7iNv1bC"
      },
      "source": [
        "Relational Languages\n",
        "\n",
        "- User only needs to specify the answer that they want, not how to compute it.\n",
        "- Specificy == Describe\n",
        "- The DBMS is responsible for efficient evaluation of the query.\n",
        "- High-end systems have a sophisticated \"query optimizer\" that can rewrite queries and search for optimal execution strategies.\n",
        "\n",
        "SQL History\n",
        "\n",
        "- IBM's first query language was called \"SQUARE\".\n",
        "- Current standard is SQL:2016\n",
        "- SQL:2016 - JSON, Polymorphic tables\n",
        "- SQL:2011 - Temporal DBs, Pipelined DML\n",
        "- SQL:2008 - Truncation, Fancy Sorting\n",
        "- SQL:2003 - XML, Windows, Sequences, Auto-Gen IDs.\n",
        "- SQL:1999 - Regex, Triggers, OO\n",
        "\n",
        "- Data Manipulation Language (DML)\n",
        "- Data Definition Language (DDL)\n",
        "- Data Control Language (DCL)\n",
        " \n",
        "- SQL is based on bags (duplicates) not sets (no duplicates).\n",
        "\n",
        "\n",
        "Aggregations + Group By\n",
        "String / Date / Time Operations\n",
        "Output Control + Redirection\n",
        "Nested Queries\n",
        "Common Table Expressions\n",
        "Window Functions\n",
        "\n",
        "Aggregates\n",
        "Functions that return a single value from a bag of tuples:\n",
        "- AVG(col)→ Return the average col value.\n",
        "- MIN(col)→ Return minimum col value.\n",
        "- MAX(col)→ Return maximum col value.\n",
        "- SUM(col)→ Return sum of values in col.\n",
        "- COUNT(col)→ Return # of values for col.\n",
        "- Distinct Aggregates : COUNT, SUM, AVG support DISTINCT\n",
        "\n",
        "\n",
        "Group By\n",
        "- Project tuples into subsets and calculate aggregates against each subset. \n",
        "\n",
        "Having\n",
        "- Filters results based on aggregation computation.\n",
        "\n",
        "String Operations\n",
        "SQL-92   | Sensitive \t| Single  Only\n",
        "Postgres | Sensitive\t| Single Only\n",
        "MySQL    | Insensitive | Single/Double\n",
        "SQLite   | Sensitive   | Single/Double\n",
        "DB2      | Sensitive   | Single Only\n",
        "Oracle   | Sensitive   | Single Only\n",
        "\n",
        "- LIKE is used for string matching. \n",
        "  - String-matching operators\n",
        "\t  - '%' Matches any substring (including empty strings).\n",
        "\t  - '_' Match any one character\n",
        " - SQL standard says to use || operator to concatenate two or more strings together.\n",
        "\n",
        "- DATE/TIME OPERATIONS  \n",
        "\n",
        "- Operations to manipulate and modify DATE/TIME attributes\n",
        "\n",
        "Output Redirection\n",
        "\n",
        "Store query results in another table\n",
        "- Table must not already be defined.\n",
        "- Table wil have the same # columns with the same types as the input.\n",
        "- INSERT INTO CourseIds (SELECT DISTINCT cid FROM enrolled); SQL92\n",
        "\n",
        "Output Control\n",
        "- Order BY <column*> [ASC | DESC]\n",
        "- SELECT sid, grade FROM enrolled WHERE cid = '15-721' ORDER BY grade\n",
        "- LIMIT <count> [offset]\n",
        "\n",
        "Nested Queries\n",
        "- Queries containing other queries.\n",
        "- They are often difficult to optimize.\n",
        "- Inner queries can appear (almost) anywhere in query.\n",
        "- SELECT name FROM student WHERE sid IN (SELECT sid FROM enrolled)\n",
        "- ALL - Must satisfy expression for all rows in the sub-query.\n",
        "- ANY - Must satisfy expression for at least one row in the sub-query.\n",
        "- IN  - Equivalent to '=ANY()' .\n",
        "- EXISTS -  At least one row is returned.\n",
        "\n",
        "Window Functions\n",
        "- Performs a \"sliding\" calculation across a set of tuples that are related.\n",
        "- Like an aggregation but tuples are not grouped into a single output tuples.\n",
        "- SELECT ... FUNC-NAME(...) OVER (...) FROM tableName\n",
        "- FUNC-NAME: Aggregation Functions Special Functions\n",
        "- OVER: How to \"slice\" up data - Can also sort\n",
        "   - Use PARTITION BY to specify group.  OVER (PARTITION BY cid)\n",
        "- Aggregation functions: Anything that we discussed earlier\n",
        "- Special window functions: \n",
        "   - ROW_NUMBER() :  # of the current row\n",
        "   - RANK() :  Order position of the current row.\n",
        "- SELECT cid, sid, ROW_NUMBER() OVER (PARTITION BY cid) FROM enrolled ORDER BY cid \n",
        "\n",
        "Common Table Expressions\n",
        "\n",
        "- Provides a way to write auxiliary statements for use in a larger query.\n",
        "- WITH cteName AS (\n",
        "\tSELECT 1\n",
        ")\n",
        "SELECT * FROM cteName\n",
        "\n",
        "CTE Recursion\n",
        "- Print the sequence of numbers from 1 to 10\n",
        "- WITH RECURSIVE cteSource (counter) AS (\n",
        "(SELECT 1)\n",
        "UNION ALL\n",
        "(SELECT counter + 1 FROM cteSource\n",
        "WHERE counter < 10)\n",
        ")\n",
        "SELECT * FROM cteSource\n",
        "\n",
        "We now understand what a database looks like at a logical level and how to write queries to read/write data (e.g., using SQL).\n",
        "\n",
        "We will next learn how to build software that manages a database (i.e., a DBMS)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9p2pBqKxKse"
      },
      "source": [
        "## 03-04 Database Storage "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u56a2jXOxN6D"
      },
      "source": [
        "**Disk-Based Architecture**\n",
        "\n",
        "- The DBMS assumes that the primary storage location of the database is on non-volatile disk.\n",
        "\n",
        "- The DBMS's components manage the movement of data between non-volatile and volatile storage.\n",
        "\n",
        "![Img](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/ComputerMemoryHierarchy.svg/800px-ComputerMemoryHierarchy.svg.png \"abc\")\n",
        "\n",
        "[Latency numbers every programmer should know](https://gist.github.com/hellerbarde/2843375)\n",
        "\n",
        "### Latency numbers every programmer should know\n",
        "    L1 cache reference ......................... 0.5 ns\n",
        "    Branch mispredict ............................ 5 ns\n",
        "    L2 cache reference ........................... 7 ns\n",
        "    Mutex lock/unlock ........................... 25 ns\n",
        "    Main memory reference ...................... 100 ns             \n",
        "    Compress 1K bytes with Zippy ............. 3,000 ns  =   3 µs\n",
        "    Send 2K bytes over 1 Gbps network ....... 20,000 ns  =  20 µs\n",
        "    SSD random read ........................ 150,000 ns  = 150 µs\n",
        "    Read 1 MB sequentially from memory ..... 250,000 ns  = 250 µs\n",
        "    Round trip within same datacenter ...... 500,000 ns  = 0.5 ms\n",
        "    Read 1 MB sequentially from SSD* ..... 1,000,000 ns  =   1 ms\n",
        "    Disk seek ........................... 10,000,000 ns  =  10 ms\n",
        "    Read 1 MB sequentially from disk .... 20,000,000 ns  =  20 ms\n",
        "    Send packet CA->Netherlands->CA .... 150,000,000 ns  = 150 ms\n",
        "\n",
        "\n",
        "Assuming ~1GB/sec SSD\n",
        "\n",
        "![Visual representation of latencies](http://i.imgur.com/k0t1e.png)\n",
        "\n",
        "Visual chart provided by [ayshen](https://gist.github.com/ayshen)\n",
        "\n",
        "Data by [Jeff Dean](http://research.google.com/people/jeff/)\n",
        "\n",
        "Originally by [Peter Norvig](http://norvig.com/21-days.html#answers)\n",
        "\n",
        "**Sequential VS. Random Access**\n",
        "\n",
        "Random access on non-volatile storage is usually much slower than sequential access.\n",
        "\n",
        "DBMS will want to maximize sequential access.\n",
        "-  Algorithms try to reduce number of writes to random pages so that data is stored in contiguous blocks.\n",
        "-  Allocating multiple pages at the same time is called an extent.\n",
        "\n",
        "**System Design Goals**\n",
        "\n",
        "- Allow the DBMS to manage databases that exceed the amount of memory available.\n",
        "- Reading/writing to disk is expensive, so it must be managed carefully to   void large stalls and performance degradation.\n",
        "- Random access on disk is usually much slower than sequential access, so the DBMS will want to maximize sequential access.\n",
        "\n",
        "**Disk-Oriented DBMS**\n",
        "\n",
        "\n",
        "- Database File\n",
        "\n",
        "![Img](https://raw.githubusercontent.com/dbremont/Notas/main/assets/img-database-file-01.jpg)\n",
        "\n",
        "- Buffer Pools\n",
        "- Execution Engine\n",
        "  - Get page #2 to teh buffer pool, if the page is not in the pool it must(veriricar) be put in the pool. Return back a pointer to page #2\n",
        "\n",
        "**Why Not Use The OS?**\n",
        "\n",
        "- The DBMS can use memory mapping (mmap) to store the contents of a file into the address space of a program.\n",
        "\n",
        "- The OS is responsible for moving the pages of the file in and out of momory, os the DBMS does't need to worry about it.\n",
        "\n",
        "- What if we allow multiple threads to access the mmap files to hide page fault stalls?\n",
        "\n",
        "- This works good enough for read-only access.\n",
        "- It is complicated when there are multiple writers…\n",
        "\n",
        "- Virtual Memory , Physical Memory\n",
        "\n",
        "- **TODO** Replicate **nmap** claim.\n",
        "\n",
        "There are some solutions to this problem:\n",
        "- madvise: Tell the OS how you expect to read certain pages.\n",
        "- mlock: Tell the OS that memory ranges cannot be paged out.\n",
        "- msync: Tell the OS to flush memory ranges out to disk.\n",
        "\n",
        "Full nmap usage:\n",
        "- monetdb,\n",
        "- lmdb,\n",
        "- revenddb,\n",
        "- leveldb,\n",
        "- elasticsearch,\n",
        "\n",
        "Partial Use:\n",
        "- mongoDB,\n",
        "- memsql,\n",
        "- sqlite,\n",
        "- influxdb\n",
        "\n",
        "DBMS (almost) always wants to control things\n",
        "itself and can do a better job than the OS.\n",
        "\n",
        "-  Flushing dirty pages to disk in the correct order.\n",
        "- Specialized prefetching.\n",
        "- Buffer replacement policy.\n",
        "- Thread/process scheduling.\n",
        "- The OS is **not** your friend.\n",
        "\n",
        "**Database Storage**\n",
        "\n",
        "- Problem 1: How the DBMS represents the database in files on disk.\n",
        "- Problem 2: HOw the DBMS manages its memory and moves data back-and-forth from disk.\n",
        "\n",
        "- File Storage\n",
        "- Page Layout\n",
        "- Tuple Layout\n",
        "\n",
        "\n",
        "The DBMS stores a database as one or more files on disk typically in a proprietary format.\n",
        "-  The OS doesn't know anything about the contents of these files.\n",
        "\n",
        "Early systems in the 1980s used custom filesystems on raw storage.\n",
        "- Some \"enterprise\" DBMSs still support this.\n",
        "- Most newer DBMSs do not do this.\n",
        "\n",
        "**Storage Manager**\n",
        "\n",
        "The storage manager is responsible for maintaining a database's files.\n",
        "- Some do their own scheduling for reads and writes to improve spatial and temporal locality of pages.\n",
        "\n",
        "It organizes the files as a collection of pages.\n",
        "- Tracks data read/written to pages.\n",
        "- Tracks the available space.\n",
        "\n",
        "**Database Pages**\n",
        "\n",
        "A page is a fixed-size block of data.\n",
        "- It can contain tuples, meta-data, indexes, log records…\n",
        "- Most systems do not mix page types.\n",
        "- Some systems require a page to be self-contained.\n",
        "\n",
        "Each page is given a unique identifier.\n",
        "- The DBMS uses an indirection layer to map page IDs to physical locations.\n",
        "\n",
        "There are three different notions of\n",
        "\"pages\" in a DBMS:\n",
        "- Hardware Page (usually 4KB)\n",
        "- OS Page (usually 4KB)\n",
        "- Database Page (512B-16KB)\n",
        "\n",
        "A hardware page is the largest block of data that the storage device can guarantee failsafe writes.\n",
        "\n",
        "4kb\n",
        "- sqlite,\n",
        "- ibm db2,\n",
        "- oracle\n",
        "\n",
        "8kb\n",
        "- microsoft sql server,\n",
        "- porgresql\n",
        "\n",
        "16kb\n",
        "- mysql\n",
        "\n",
        "**Database Heap**\n",
        "\n",
        "A *heap file* is an unordered collection of pages with tuples that are stored in random order.\n",
        "- Create / Get / Write / Delete Page\n",
        "- Must also support iterating over all pages.\n",
        "\n",
        "Two ways to represent a heap file:\n",
        "* Linked List\n",
        "* Page Directory\n",
        "\n",
        "- It is easy to find pages if there is only a single heap file.\n",
        "- Need meta-data to keep track of what pages exist in multiple files and which ones have free space\n",
        "\n",
        "Link List\n",
        "\n",
        "- Maintain a header page at the beginning of the file that stores two pointers:\n",
        "  - HEAD of the free page list.\n",
        "  - HEAD of the data page list.\n",
        "\n",
        "- Each page keeps track of how many free slots they currently have.\n",
        "\n",
        "Page Directory\n",
        "\n",
        "- The DBMS maintains special pages that tracks the location of data pages in the database files.\n",
        "\n",
        "- The directory also records the number of free slots per page.\n",
        "- Must make sure that the directory pages are in sync with the data pages.\n",
        "\n",
        "**Page Header** \n",
        "\n",
        "Every page contains a header of metadata about the page's contents.\n",
        "- Page Size\n",
        "- Checksum\n",
        "- DBMS Version\n",
        "- Transaction Visibility\n",
        "- Compression Information\n",
        "\n",
        "- Some systems require pages to be selfcontained (e.g., Oracle).\n",
        "\n",
        "- ![Page Header](https://raw.githubusercontent.com/dbremont/Notas/main/assets/img-page-02.jpg)\n",
        "\n",
        "\n",
        "**Page Layout**\n",
        "\n",
        "For any page storage architecture, we now need to decide how to organize the data inside of the page.\n",
        "\n",
        "- We are still assuming that we are only storing tuples.\n",
        "\n",
        "Two approaches:\n",
        "- Tuple-oriented\n",
        "- Log-structure\n",
        "\n",
        "How to store tuples in a page?\n",
        "**Strawman Idea**: Keep track of the number of tuples in a page and then just append a new tuple to the end.\n",
        "\n",
        "- What happens if we delete a tuple?\n",
        "- What happens if we have a variablelength attribute?\n",
        "\n",
        "**Slotted Pages**\n",
        "\n",
        "- The most common layout scheme is called *slotted pages*.\n",
        "- The slot array maps \"slots\" to the tuples' starting position offsets.\n",
        "- The header keeps track of:\n",
        "\n",
        "  - The # of used slots\n",
        "  - The offset of the starting location of the last slot used.\n",
        "\n",
        "**Record IDS**\n",
        "\n",
        "- The DBMS needs a way to keep track of individual tuples.\n",
        "\n",
        "- Each tuple is assigned a unique record identifier.\n",
        "  -  Most common: page_id + offset/slot\n",
        "  - Can also contain file location info.\n",
        "\n",
        "- An application cannot rely on these IDs to mean anything.\n",
        "\n",
        "**Tuple Layout**\n",
        "\n",
        "- A tuple is essentially a sequence of bytes.\n",
        "- It's the job of the DBMS to interpret those bytes into attribute types and \n",
        "values.\n",
        "- Each tuple is prefixed with a header that contains meta-data about it. \n",
        "  - Visibility info (concurrency control)\n",
        "  - Bit Map for NULL values.\n",
        "- We do **not** need to store meta-data about the schema.\n",
        "- Attributes are typically stored in the order that you specify them when you \n",
        "create the table.\n",
        "- This is done for software engineering reasons (i.e., simplicity).\n",
        "- However, it might be more efficient to lay them out differently.\n",
        "\n",
        "![Tuple Structure](https://raw.githubusercontent.com/dbremont/Notas/main/assets/img-tuple-03.jpg)\n",
        "\n",
        "DBMS can physically denormalize (e.g., \"pre join\") related tuples and store them together in the same page. \n",
        "- Potentially reduces the amount of I/O for common workload patterns.\n",
        "- Can make updates more expensive.\n",
        "\n",
        "```sql\n",
        "CREATE TABLE foo (\n",
        "a INT PRIMARY KEY,\n",
        "b INT NOT NULL,\n",
        ");\n",
        "\n",
        "CREATE TABLE bar (\n",
        "c INT PRIMARY KEY,\n",
        "a INT\n",
        "⮱REFERENCES foo (a),\n",
        ");\n",
        "```\n",
        "\n",
        "- ```foo Header a b c c c …```\n",
        "- foo: ```a b```\n",
        "- bar: ```c c c …```\n",
        "\n",
        "- Not a new idea.\n",
        "  -  IBM System R did this in the 1970s.\n",
        "  -  Several NoSQL DBMSs do this without calling it physical denormalization.\n",
        "  - Rethinkdb,\n",
        "  - couchdb,\n",
        "  - marklogic,\n",
        "  - ravendb,\n",
        "  - mongodb\n",
        "\n",
        "- Database is organized in pages.\n",
        "- Different ways to track pages.\n",
        "- Different ways to store pages.\n",
        "- Different ways to store tuples.\n",
        "\n",
        "**Log-Structured File Organization**\n",
        "\n",
        "- Instead of storing tuples in pages, the DBMS only stores log records.\n",
        "- The system appends log records to the file of how the database was modified:\n",
        "  - Inserts store the entire tuple.\n",
        "  - Deletes mark the tuple as deleted.\n",
        "  - Updates contain the delta of just the attributes that were modified.\n",
        "\n",
        "![Page with log structure](https://raw.githubusercontent.com/dbremont/Notas/main/assets/img-log-structure-04.jpg)\n",
        "\n",
        "- To read a record, the DBMS scans the log backwards and \"recreates\" the tuple to find what it needs.\n",
        "\n",
        "- Build indexes to allow it to jump to locations in the log.\n",
        "\n",
        "- Periodically compact the log.\n",
        "\n",
        "  - apache hbase,\n",
        "  - cassandra,\n",
        "  - leveldb,\n",
        "  - rocksdb\n",
        " \n",
        "- Compaction coalesces larger log files into smaller files by removing unnecessary records.\n",
        "\n",
        "**Tuple Storage**\n",
        "\n",
        "A tuple is essentially a sequence of bytes. It's the job of the DBMS to interpret those bytes into attribute types and values.\n",
        "\n",
        "The DBMS's catalogs contain the schema information about tables that the system uses to figure out the tuple's layout.\n",
        "\n",
        "**Data Representation**\n",
        "\n",
        "- ```INTEGER/BIGINT/SMALLINT/TINYINT```(C/C++ Representation)\n",
        "\n",
        "- ```FLOAT/REAL vs. NUMERIC/DECIMAL```  (IEEE-754 Standard / Fixed-point Decimals)\n",
        "\n",
        "- ```VARCHAR/VARBINARY/TEXT/BLOB```     (Header with length, followed by data bytes)\n",
        "\n",
        "- ```TIME/DATE/TIMESTAMP``` (32/64-bit integer of (micro)seconds since Unix epoch)\n",
        "\n",
        "**Variable Precision Numbers**\n",
        "\n",
        "- Inexact, variable-precision numeric type that uses the \"native\" C/C++ types.\n",
        "  - Examples: FLOAT, REAL/DOUBLE\n",
        "\n",
        "- Store directly as specified by IEEE-754.\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "int main(int argc, char* argv[]) {\n",
        "  float x = 0.1;\n",
        "  float y = 0.2;\n",
        "  printf(\"x+y = %f\\n\", x+y);\n",
        "  printf(\"0.3 = %f\\n\", 0.3);\n",
        "}\n",
        "\n",
        "x+y = 0.300000\n",
        "0.3 = 0.300000\n",
        "```\n",
        "\n",
        "**Fixed Precision Numbers**\n",
        "\n",
        "Numeric data types with (potentially) arbitrary precision and scale. Used when  rounding errors are unacceptable.\n",
        "- NUMERIC, \n",
        "- DECIMAL\n",
        "\n",
        "Many different implementations.\n",
        "- Example: Store in an exact, variable-length binary\n",
        "representation with additional meta-data.\n",
        "- Can be less expensive if you give up arbitrary precision.\n",
        "\n",
        "**Postgress - Numeric**\n",
        "\n",
        "```c\n",
        "typedef unsigned char NumericDigit;\n",
        "typedef struct {\n",
        "  int ndigits; // # of Digits\n",
        "  int weight;  // Weight of 1st Digit\n",
        "  int scale;  // Scale Factor\n",
        "  int sign;  // Positive/Negative/NaN\n",
        "  NumericDigit *digits; // // Digit Storage\n",
        "} numeric;\n",
        "```\n",
        "\n",
        "**MySQL Numeric**\n",
        "\n",
        "```c\n",
        "typedef int32 decimal_digit_t;\n",
        "struct decimal_t {\n",
        "  int \n",
        "    intg,  // # of Digits Before Point\n",
        "    frac,  // # of Digits After Point \n",
        "    len;   // Length (Bytes)\n",
        "  bool sign; // Positive/Negative\n",
        "  decimal_digit_t *buf; // Digit Storage\n",
        "};\n",
        "```\n",
        "\n",
        "**Larges Values**\n",
        "\n",
        "- Most DBMSs don't allow a tuple to exceed the size of a single page.\n",
        "- To store values that are larger than a page, the DBMS uses separate\n",
        "overflow storage pages.\n",
        "  - Postgres: TOAST (>2KB)\n",
        "  - MySQL: Overflow (>½ size of page)\n",
        "  - SQL Server: Overflow (>size of page)\n",
        "\n",
        "**External Value Storage**\n",
        "\n",
        "Some systems allow you to store a really large value in an external file.\n",
        "\n",
        "Treated as a BLOB type.\n",
        "- Oracle: BFILE data type\n",
        "- Microsoft: FILESTREAM data type\n",
        "\n",
        "The DBMS cannot manipulate the contents of an external file.\n",
        "- No durability protections.\n",
        "- No transaction protections.\n",
        "\n",
        "**System Catalogs**\n",
        "\n",
        "A DBMS stores meta-data about databases in its internal catalogs.\n",
        "- Tables, columns, indexes, views\n",
        "- Users, permissions\n",
        "- Internal statistics\n",
        "\n",
        "Almost every DBMS stores the database's catalog inside itself (i.e., as tables).\n",
        "- Wrap object abstraction around tuples.\n",
        "- Specialized code for \"bootstrapping\" catalog tables.\n",
        "\n",
        "You can query the DBMS’s internal *INFORMATION_SCHEMA* catalog to get info about\n",
        "the database. \n",
        "- ANSI standard set of read-only views that provide info about all the tables, views, columns, and procedures in a database\n",
        "\n",
        "DBMSs also have non-standard shortcuts to retrieve this information.\n",
        "\n",
        "**Accessing Table Schema**\n",
        "\n",
        "```sql\n",
        "SELECT *\n",
        "FROM INFORMATION_SCHEMA.TABLES\n",
        "WHERE table_catalog = '<db name>';\n",
        "```\n",
        "\n",
        "**Database Workloads**\n",
        "\n",
        "On-Line Transaction Processing (OLTP)\n",
        "- Fast operations that only read/update a small amount of data each time.\n",
        "\n",
        "On-Line Analytical Processing (OLAP)\n",
        "- Complex queries that read a lot of data to compute aggregates.\n",
        "\n",
        "Hybrid Transaction + Analytical Processing\n",
        "- OLTP + OLAP together on the same database instance\n",
        "\n",
        "![workoad graph](https://raw.githubusercontent.com/dbremont/Notas/main/assets/img-workload-05.jpg)\n",
        "\n",
        "[Article](https://cacm.acm.org/magazines/2011/6/108651-10-rules-for-scalable-performance-in-simple-operation-datastores/fulltext)\n",
        "\n",
        "**OLTP**\n",
        "\n",
        "On-line Transaction Processing:\n",
        "- Simple queries that read/update a small amount of data that is related to a single entity in the database.\n",
        "\n",
        "- This is usually the kind of application that people build first.\n",
        "\n",
        "**OLAP**\n",
        "\n",
        "\n",
        "On-line Analytical Processing:\n",
        "- Complex queries that read large portions of the database spanning multiple entities.\n",
        "\n",
        "You execute these workloads on the data you have collected from your OLTP application(s).\n",
        "\n",
        "**Data Storage Models**\n",
        "\n",
        "The DBMS can store tuples in different ways that are better for either OLTP or OLAP workloads.\n",
        "\n",
        "We have been assuming the n-ary storage model (aka \"row storage\") so far this semester.\n",
        "\n",
        "**N-ARY Storage Model (NSM)**\n",
        "\n",
        "- The DBMS stores all attributes for a single tuple contiguously in a page.\n",
        "\n",
        "- Ideal for OLTP workloads where queries tend to operate only on an individual entity and insertheavy workloads.\n",
        "\n",
        "- The DBMS stores all attributes for a single tuple contiguously in a page.\n",
        "\n",
        "```sql\n",
        "SELECT * FROM useracct\n",
        "WHERE userName = ?\n",
        "AND userPass = ?\n",
        "```\n",
        "\n",
        "- Index maps of data to locations.\n",
        "\n",
        "Advantages\n",
        "\n",
        "- Fast inserts, updates, and deletes.\n",
        "- Good for queries that need the entire tuple.\n",
        "\n",
        "**Decomposition Storage Model (DSM)** \"column store\"\n",
        "\n",
        "The DBMS stores the values of a single attribute for all tuples contiguously in a page. \n",
        "\n",
        "- Ideal for OLAP workloads where read-only queries perform large scans over a subset of the table’s attributes.\n",
        "\n",
        "**Tuple Indentification**\n",
        "\n",
        "- Fixed-length Offsets\n",
        "- Embedded Tuple Ids\n",
        "\n",
        "Advantages\n",
        "- Reduces the amount wasted I/O because the DBMS only\n",
        "reads the data that it needs.\n",
        "- Better query processing and data compression (more on\n",
        "this later).\n",
        "\n",
        "Disadvantages\n",
        "- Slow for point queries, inserts, updates, and deletes\n",
        "because of tuple splitting/stitching\n",
        "\n",
        "The storage manager is not entirely independent\n",
        "from the rest of the DBMS.\n",
        "\n",
        "It is important to choose the right storage model for the target workload:\n",
        "- OLTP = Row Store\n",
        "- OLAP = Column Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuEo5iZjXQC0"
      },
      "source": [
        "## 05 "
      ]
    }
  ]
}