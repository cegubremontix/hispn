{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kafka: a Distributed Messaging System for Log Processing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbremont/Notas/blob/main/Papers/Computacion/Kafka%3A_a_Distributed_Messaging_System_for_Log_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckPYOCXifngv"
      },
      "source": [
        "Log  processing  has  become  a  critical  component  of  the  data \n",
        "pipeline for consumer internet companies. We introduce Kafka, a \n",
        "distributed messaging system that we developed for collecting and \n",
        "delivering high volumes of log data with low latency. Our system \n",
        "incorporates  ideas  from  existing  log  aggregators  and  messaging \n",
        "systems,  and  is  suitable  for  both  offline  and  online  message \n",
        "consumption.  We  made  quite  a  few  unconventional  yet  practical \n",
        "design choices in Kafka to make our system efficient and scalable. \n",
        "Our experimental results show that Kafka has superior \n",
        "performance  when  compared  to  two  popular  messaging  systems. \n",
        "We  have  been  using  Kafka  in  production  for  some  time  and  it  is \n",
        "processing hundreds of gigabytes of new data each day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lkbcfi_kP3r"
      },
      "source": [
        "Distributed messaging system that collect and deliver  high volumes of log data with low latency.\n",
        "\n",
        "- messaging system?\n",
        "- low latency?\n",
        "\n",
        "- What other messaging systems are there?\n",
        "\n",
        "\n",
        "'Log data':\n",
        "- user logings,\n",
        "-  clicks,\n",
        "- \"likes\",\n",
        "- sharing',  \n",
        "- comments,\n",
        "- sysetm utilization,\n",
        "- cpu,\n",
        "- memory,\n",
        "\n",
        "I can play with the idea, recolecting metrics, in my computer, of mouse moves, key press, memory use\n",
        "- And store those as events,\n",
        "\n",
        "\n",
        "Log data is larger then 'real' data.\n",
        "\n",
        "Every day 'China Mobile' collects 5-8TB of various user activity events.\n",
        "\n",
        "Back in the day the system for processing this log information usually scrapce physical log files. Now there are many 'distributed log aggregators' like **Facebook Scribe**, **Yahoo's Data Highway**, **Claudera's Flume**\n",
        "\n",
        "Kafka is bouth \n",
        "- a log agregator,\n",
        "- a messaging system\n",
        "\n",
        "Kafka simplifies infraestruc because it is used for offline and online processing of 'logs events'\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM_vM1dlo6JE"
      },
      "source": [
        "## Related Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3Wz1P0To9Tm"
      },
      "source": [
        "JMS: api, features, garantees.\n",
        "- Does it alows to batch events in one request?\n",
        "- What is the distributed support of JMS\n",
        "\n",
        " What is the implementation detail leaks by 'Flume'?\n",
        "\n",
        "Push vs Pull model\n",
        "\n",
        "Why Kafka uses the pull model?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oggy5iYstMM"
      },
      "source": [
        "##  Kafka Architecture and Desigg Principles"
      ]
    }
  ]
}