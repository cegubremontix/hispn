{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark: Cluster Computing with Working Sets.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbremont/Notas/blob/main/Papers/Computacion/Spark%3A_Cluster_Computing_with_Working_Sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF_F9Uvsmitj"
      },
      "source": [
        "MapReduce and its variants have been highly successful\n",
        "in implementing large-scale data-intensive applications\n",
        "on commodity clusters. However, most of these systems\n",
        "are built around an acyclic data flow model that is not\n",
        "suitable for other popular applications. This paper fo-\n",
        "cuses on one such class of applications: those that reuse\n",
        "a working set of data across multiple parallel operations.\n",
        "This includes many iterative machine learning algorithms,\n",
        "as well as interactive data analysis tools. We propose a\n",
        "new framework called Spark that supports these applica-\n",
        "tions while retaining the scalability and fault tolerance of\n",
        "MapReduce. To achieve these goals, Spark introduces an\n",
        "abstraction called resilient distributed datasets (RDDs).\n",
        "An RDD is a read-only collection of objects partitioned\n",
        "across a set of machines that can be rebuilt if a partition\n",
        "is lost. Spark can outperform Hadoop by 10x in iterative\n",
        "machine learning jobs, and can be used to interactively\n",
        "query a 39 GB dataset with sub-second response time"
      ]
    }
  ]
}