{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2.7.18 64-bit",
      "name": "python2718jvsc74a57bd0f92b2924b84ff19c1c3dc485f7644d4486f64738191026bf8e6de303969141b5"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "f92b2924b84ff19c1c3dc485f7644d4486f64738191026bf8e6de303969141b5"
      }
    },
    "orig_nbformat": 2,
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbremont/Notas/blob/main/Libros/Aprendisaje%20Automatico/Deep%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFUy52qhps-K"
      },
      "source": [
        "* [Deep Learning - Ian Goodfellow and Yoshua Bengio and Aaron Courville](https://www.deeplearningbook.org/)\n",
        "  \n",
        "* [Notes on the Deep Learning book from Ian Goodfellow, Yoshua Bengio and Aaron Courville (2016)](https://github.com/hadrienj/deepLearningBook-Notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSkvFfWApoQj"
      },
      "source": [
        "Table of Contents\n",
        "Acknowledgements\n",
        "Notation\n",
        "1 Introduction\n",
        "Part I: Applied Math and Machine Learning Basics\n",
        "2 Linear Algebra\n",
        "3 Probability and Information Theory\n",
        "4 Numerical Computation\n",
        "5 Machine Learning Basics\n",
        "Part II: Modern Practical Deep Networks\n",
        "6 Deep Feedforward Networks\n",
        "7 Regularization for Deep Learning\n",
        "8 Optimization for Training Deep Models\n",
        "9 Convolutional Networks\n",
        "10 Sequence Modeling: Recurrent and Recursive Nets\n",
        "11 Practical Methodology\n",
        "12 Applications\n",
        "Part III: Deep Learning Research\n",
        "13 Linear Factor Models\n",
        "14 Autoencoders\n",
        "15 Representation Learning\n",
        "16 Structured Probabilistic Models for Deep Learning\n",
        "17 Monte Carlo Methods\n",
        "18 Confronting the Partition Function\n",
        "19 Approximate Inference\n",
        "20 Deep Generative Models\n",
        "Bibliography\n",
        "Index\n",
        "\n",
        "\n",
        "15 Representation Learning\n",
        "\n",
        "data representation.\n",
        "- Representation of Numbers: Roman Numerals vs Indo-Arabic Numerals.\n",
        "- A Good Representation is one that makes a subsequent learning task easier. The choice of representation will usually depend on the choice of the subsequent learning task.\n",
        "\n",
        "- We can think of feedforward networks trained by supervised learning as performing a kind of \"representation learning\".\n",
        "- Linearly Separable.\n",
        "\n",
        "- Representation learning is interesting because it provides one way to perform unsupervised and semi-supervised learning.\n",
        "\n",
        "- Learning good representations of the unlabeled data, to appply to the labeled dataset part.\n",
        "\n",
        "- Pretraining.\n",
        "\n",
        "- Transfer Learning.\n",
        " \n"
      ]
    }
  ]
}